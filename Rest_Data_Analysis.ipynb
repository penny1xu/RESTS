{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/penny1xu/RESTS/blob/main/Rest_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJff6UchHVNB",
        "outputId": "377c9df2-0c21-446a-e2cd-4ef9e1b2715e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting censusgeocode\n",
            "  Downloading censusgeocode-0.5.2-py3-none-any.whl (9.2 kB)\n",
            "Collecting requests[security]<3,>=2.27.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting requests-toolbelt<1,>=0.9.0\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from requests-toolbelt<1,>=0.9.0->censusgeocode) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt<1,>=0.9.0->censusgeocode) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt<1,>=0.9.0->censusgeocode) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt<1,>=0.9.0->censusgeocode) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt<1,>=0.9.0->censusgeocode) (3.0.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (2.0.12)\n",
            "Installing collected packages: requests, requests-toolbelt, censusgeocode\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed censusgeocode-0.5.2 requests-2.28.1 requests-toolbelt-0.9.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rets\n",
            "  Downloading rets-1.0.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from rets) (2.28.1)\n",
            "Collecting xmltodict>=0.11.0\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from rets) (1.15.0)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from rets) (0.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (1.24.3)\n",
            "Installing collected packages: xmltodict, rets\n",
            "Successfully installed rets-1.0.0 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install censusgeocode\n",
        "!pip install rets\n",
        "import csv\n",
        "import pandas as pd\n",
        "import censusgeocode as cg\n",
        "import numpy as np\n",
        "import sys\n",
        "from rets import Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "itgrCM-_Lglt"
      },
      "outputs": [],
      "source": [
        "def add(lo_left,lo_right,la_left,la_right):\n",
        "    a = 0.008 #调整经纬度改这里\n",
        "    lo_left -= a\n",
        "    lo_right += a\n",
        "    la_left -= a\n",
        "    la_right += a\n",
        "    return lo_left, lo_right, la_left, la_right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NtLir-mDWsiX"
      },
      "outputs": [],
      "source": [
        "def judgeType(item):\n",
        "  if(item['PropertyType'] == 'Residential' and item['PropertySubType'] == 'Single Family Residence'):#改type在这里\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7ltm-qDfls5y"
      },
      "outputs": [],
      "source": [
        "def calSqr(sqr):\n",
        "    if sqr <= 1100:\n",
        "        left = sqr - 100\n",
        "        right = sqr + 100\n",
        "    elif sqr <= 2200:\n",
        "        left = sqr - 200\n",
        "        right = sqr + 200\n",
        "    else:\n",
        "        left = sqr - 300\n",
        "        right = sqr + 300\n",
        "    return left, right"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calYear(year):\n",
        "  if year < 1990:\n",
        "     begin = 0 \n",
        "     end = 1989\n",
        "  elif year >= 1990 and year < 2011:\n",
        "    begin = 1990\n",
        "    end = 2010\n",
        "  elif year >= 2011 and year < 2022:\n",
        "    begin = 2011\n",
        "    end = 2021\n",
        "  else:\n",
        "    begin = 2022\n",
        "    end = 9999\n",
        "  return begin,end"
      ],
      "metadata": {
        "id": "V9PMU59IqZfn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjWpgj_i_17w"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j-bVvyh4HrtB"
      },
      "outputs": [],
      "source": [
        "def FindifNull(research, lo_left,lo_right,la_left,la_right, status, date, sq_left, sq_right,begin_year,end_year):\n",
        "  #经纬度查找\n",
        "  filter = {\n",
        "        \"Longitude\": \"{}-{}\".format(lo_left, lo_right),\n",
        "        \"Latitude\": \"{}-{}\".format(la_left, la_right),\n",
        "        \"MlsStatus\" : \"{}\".format(status),\n",
        "        \"CloseDate\" : \"{}\".format(date),\n",
        "        \"LivingArea\" : \"{}-{}\".format(sq_left, sq_right),\n",
        "        \"YearBuilt\" :\"{}-{}\".format(begin_year, end_year)\n",
        "        }\n",
        "  result = research.search(resource='Property', resource_class='Property', search_filter=filter)\n",
        "  lis = []\n",
        "  count = 0\n",
        "  di ={}\n",
        "  df = pd.DataFrame()\n",
        "  for item in result:\n",
        "    if(judgeType(item)):\n",
        "      df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True) #?\n",
        "      count += 1\n",
        "      di = item # 存表头\n",
        "  for key in di:\n",
        "    lis.append(key)\n",
        "  if(count >= 5): \n",
        "    df = df.T\n",
        "    df.columns = lis\n",
        "    return df\n",
        "  else:\n",
        "    lo_left, lo_right, la_left, la_right = add(lo_left,lo_right,la_left,la_right)\n",
        "    return FindifNull(research, lo_left,lo_right,la_left,la_right, status, date, sq_left, sq_right,begin_year,end_year)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwWI8C2-Wb3X"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BGJv_Nq_Hxuy"
      },
      "outputs": [],
      "source": [
        "def FindHouse(house_leftLa,house_rightLa,house_leftLo,house_rightLo,research,zip,column, sub, status, date, sq_left, sq_right,begin_year, end_year):\n",
        "  #sub，zip查找，未找到足够的自动转经纬度\n",
        "  filter = {\n",
        "        \"PostalCode\" : zip,\n",
        "        \"MlsStatus\" : \"{}\".format(status),\n",
        "        \"CloseDate\" : \"{}\".format(date),\n",
        "        \"LivingArea\" : \"{}-{}\".format(sq_left, sq_right),\n",
        "        \"YearBuilt\" :\"{}-{}\".format(begin_year, end_year)\n",
        "        }\n",
        "  result = research.search(resource='Property', resource_class='Property', search_filter=filter)\n",
        "  count = 0\n",
        "  df = pd.DataFrame()\n",
        "  for item in result: \n",
        "    if(judgeType(item)):\n",
        "      if(sub == item['SubdivisionName'].split()[0]):\n",
        "         df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True) #?\n",
        "         count += 1    \n",
        "  if(count >= 5):  \n",
        "    df = df.T\n",
        "    df.columns = column # \n",
        "    return df\n",
        "  else:\n",
        "    return FindifNull(research, house_leftLo,house_rightLo, house_leftLa, house_rightLa, status, date, sq_left, sq_right,begin_year, end_year)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FdyoCacQ9qP_"
      },
      "outputs": [],
      "source": [
        "def findfirst(result):\n",
        "  #判断是否有，不用管\n",
        "    count = 0\n",
        "    for item in result:\n",
        "        count += 1\n",
        "    if(count == 0):\n",
        "        return False\n",
        "    else:\n",
        "        return True    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QiyDiActQzMq"
      },
      "outputs": [],
      "source": [
        "def insertId(pulled_value, mls,rets_client, column2, status, date):\n",
        "  #mls查找，按照先sub + zip，后geo\n",
        "  column = []\n",
        "  for key in pulled_value:\n",
        "    column.append(key)\n",
        "  print(\"\\nThis value exists in Website\")\n",
        "  zip = pulled_value.get('PostalCode')\n",
        "  latitude = pulled_value.get('Latitude')\n",
        "  longitude = pulled_value.get('Longitude')\n",
        "  bedroom = pulled_value.get('BedroomsTotal')\n",
        "  sqr = pulled_value.get('LivingArea')\n",
        "  year = pulled_value.get('YearBuilt')\n",
        "  if(zip != \"\" and latitude != \"\" and longitude != \"\" and sqr != \"\" and year != \"\"):\n",
        "    house_leftLa = float(pulled_value.get('Latitude'))\n",
        "    house_rightLa = float(pulled_value.get('Latitude')) \n",
        "    house_leftLo = float(pulled_value.get('Longitude'))\n",
        "    house_rightLo = float(pulled_value.get('Longitude'))\n",
        "    sub = str(pulled_value.get('SubdivisionName').split()[0])\n",
        "    sqr = float(sqr)\n",
        "    year = int(year)\n",
        "    left, right = calSqr(sqr)\n",
        "    begin, end = calYear(year)\n",
        "    result1 = FindHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, rets_client,int(zip) ,column, sub, status, date, left, right,begin,end) \n",
        "    result1['FullAddress'] = result1['StreetNumber'] + \" \" + result1['StreetName']  + \", \" + result1['City'] + \", \" +result1['StateOrProvince'] + \" \" + result1['PostalCode']       \n",
        "    result1 = result1[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "  'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "  'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "  'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "  'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "  'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "  'USProperty_MUI', 'YearBuilt','LotSizeAcres','FullAddress']]\n",
        "    price = []\n",
        "    cdom_signValue = []\n",
        "    df_id = pd.DataFrame()\n",
        "\n",
        "###########################################################\n",
        "# compares\n",
        "      \n",
        "    if(status == 'SLD'): \n",
        "      for item in result1['ClosePrice']:\n",
        "        item = float(item)\n",
        "        price.append(item)\n",
        "      result1['ClosePrice'] = price\n",
        "      mean1 = result1['ClosePrice'].mean()\n",
        "      top1 = list(result1['ClosePrice'])\n",
        "      top1.sort(reverse = True)\n",
        "      top1_mean = sum(top1[0:3])/3\n",
        "      min1 = list(result1['ClosePrice'])\n",
        "      min1.sort(reverse = False)\n",
        "      median = result1['ClosePrice'].median()\n",
        "      percent_mean1 = (mean1-90)/100 ######\n",
        "      percent_Top_mean1 = (top1_mean-90)/100 ######\n",
        "      percent_Top1 = (top1_mean-90)/100 ######\n",
        "      for item in result1['CumulativeDaysOnMarket']:\n",
        "        item = int(item)\n",
        "        cdom_signValue.append(item)\n",
        "      result1['CumulativeDaysOnMarket'] = cdom_signValue\n",
        "      cdom = result1['CumulativeDaysOnMarket'].mean()\n",
        "      df_id_comp = pd.DataFrame()\n",
        "      df2_append_comp = {'Min': min1[0],'Median': median ,'Mean': mean1,'Top 3 Mean': top1_mean,'Max': top1[0] ,'CDOM': cdom}\n",
        "      df_id_comp = df_id_comp.append(df2_append_comp, ignore_index = True)\n",
        "      df3_append_comp = {'Min': None,'Median': None ,'Mean': percent_mean1,'Top 3 Mean': percent_Top_mean1,'Max': percent_Top1 ,'CDOM': None} ######\n",
        "      df_id_comp = df_id_comp.append(df3_append_comp, ignore_index = True)####\n",
        "      df4_append_comp = {'Min': None,'Median': None ,'Mean': 10,'Top 3 Mean': 20,'Max':30 ,'CDOM': None} ######\n",
        "      df_id_comp = df_id_comp.append(df4_append_comp, ignore_index = True)#####\n",
        "      df_id_comp = df_id_comp.rename(index={0: 'Comps', 1: '% above price',2: 'Est. Margin'})#####\n",
        "      df_id_comp.to_csv('{}.csv'.format(mls))\n",
        "###########################################################\n",
        "    df_id_status = pd.DataFrame()\t\t\n",
        "    for i in range(len(result1['FullAddress'])):\t\t\t\t\t\t\t\t\n",
        "      df_id_status = df_id_status.append(result1.loc[i][column2], ignore_index = True)\n",
        "    return df_id_status\n",
        "  else:\n",
        "    print('Information missing in the system!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ljfKnnerAJjw"
      },
      "outputs": [],
      "source": [
        "def insertAdd(number, name, city, state, zip, address, rets_client, column2, status, date):\n",
        "  #add查找，按照先sub + zip，后geo\n",
        "  pulled_value = {}\n",
        "  result = rets_client.search(resource = 'Property', resource_class='Property', dmql_query='(StreetNumber = {}),(StreetName = {}),(PostalCode = {})'.format(number,name,zip))\n",
        "  for item in result:\n",
        "    pulled_value = item\n",
        "  if(len(pulled_value) != 0):\n",
        "    column = []\n",
        "    for key in pulled_value:\n",
        "      column.append(key)\n",
        "    print(\"\\nThis value exists in Website\")\n",
        "    zip = pulled_value.get('PostalCode')\n",
        "    latitude = pulled_value.get('Latitude')\n",
        "    longitude = pulled_value.get('Longitude')\n",
        "    sqr = pulled_value.get('LivingArea')\n",
        "    year = pulled_value.get('YearBuilt')\n",
        "    if(zip != \"\" and latitude != \"\" and longitude != \"\" and sqr != \"\"):\n",
        "      house_leftLa = float(pulled_value.get('Latitude'))\n",
        "      house_rightLa = float(pulled_value.get('Latitude')) \n",
        "      house_leftLo = float(pulled_value.get('Longitude'))\n",
        "      house_rightLo = float(pulled_value.get('Longitude'))\n",
        "      zip = int(pulled_value.get('PostalCode'))\n",
        "      sqr = float(sqr)\n",
        "      year = int(year)\n",
        "      left, right = calSqr(sqr)\n",
        "      begin, end = calYear(year)\n",
        "      sub = str(pulled_value.get('SubdivisionName').split()[0])\n",
        "      result1 = FindHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, rets_client,zip,column, sub, status, date, left, right,begin,end)        \n",
        "      result1['FullAddress'] = result1['StreetNumber'] + \" \" + result1['StreetName']  + \", \" + result1['City'] + \", \" +result1['StateOrProvince'] + \" \" + result1['PostalCode']       \n",
        "      result1 = result1[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "  'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "  'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "  'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "  'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "  'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "  'USProperty_MUI', 'YearBuilt','LotSizeAcres','FullAddress']]\n",
        "      price = []\n",
        "      cdom_signValue = []\n",
        "      df_id = pd.DataFrame()\n",
        "\n",
        "###########################################################\n",
        "# compares\n",
        "    \n",
        "      if(status == 'SLD'): \n",
        "        for item in result1['ClosePrice']:\n",
        "          item = float(item)\n",
        "          price.append(item)\n",
        "        result1['ClosePrice'] = price\n",
        "        mean1 = result1['ClosePrice'].mean()\n",
        "        top1 = list(result1['ClosePrice'])\n",
        "        top1.sort(reverse = True)\n",
        "        top1_mean = sum(top1[0:3])/3\n",
        "        min1 = list(result1['ClosePrice'])\n",
        "        min1.sort(reverse = False)\n",
        "        percent_mean1 = (mean1 - result1['ClosePrice']) /100 ######\n",
        "        percent_Top_mean1 = (top1_mean - result1['ClosePrice']) / 100 ######\n",
        "        percent_Top1 = (top1_mean-result1['ClosePrice'])/100 ######\n",
        "        median = result1['ClosePrice'].median()\n",
        "        for item in result1['CumulativeDaysOnMarket']:\n",
        "          item = int(item)\n",
        "          cdom_signValue.append(item)\n",
        "        result1['CumulativeDaysOnMarket'] = cdom_signValue\n",
        "        cdom = result1['CumulativeDaysOnMarket'].mean()\n",
        "        df_id_comp = pd.DataFrame()\n",
        "        df2_append_comp = {'Min': min1[0],'Median': median ,'Mean': mean1,'Top 3 Mean': top1_mean,'Max': top1[0] ,'Avg. CDOM': cdom}\n",
        "        df_id_comp = df_id_comp.append(df2_append_comp, ignore_index = True)\n",
        "        df3_append_comp = {'Min': None,'Median': None ,'Mean': percent_mean1,'Top 3 Mean': percent_Top_mean1,'Max': percent_Top1 ,'CDOM': None} ######\n",
        "        df_id_comp = df_id_comp.append(df3_append_comp, ignore_index = True)####\n",
        "        df4_append_comp = {'Min': None,'Median': None ,'Mean': 10,'Top 3 Mean': 20,'Max':30 ,'CDOM': None} ######\n",
        "        df_id_comp = df_id_comp.append(df4_append_comp, ignore_index = True)#####\n",
        "        df_id_comp = df_id_comp.rename(index={0: 'Comps', 1: '% above price',2: 'Est. Margin'})#####\n",
        "        df_id_comp.to_csv('{}.csv'.format(address))\n",
        "###########################################################\n",
        "      df_id_status = pd.DataFrame()\t\t\n",
        "      for i in range(len(result1['FullAddress'])):\t\t\t\t\t\t\t\t\n",
        "        df_id_status = df_id_status.append(result1.loc[i][column2], ignore_index = True)\n",
        "      return df_id_status\n",
        "    else:\n",
        "      print('check coordinates')\n",
        "      return FindAdd(rets_client, address, city, state, zip, status, date, column2)\n",
        "  else:\n",
        "    print('check coordinates')\n",
        "    return FindAdd(rets_client, address, city, state, zip, status, date, column2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F7MCZWuKUJN-"
      },
      "outputs": [],
      "source": [
        "def FindAdd(rets_client, address, city, state, zipcode, bedroom, status, date, column2):  \n",
        "  #geo代码，在mls和address中引用\n",
        "  result = cg.address(address, city = city, state= state,zipcode = zipcode)\n",
        "  lo_left = result[0]['coordinates']['x']\n",
        "  lo_right = result[0]['coordinates']['x']\n",
        "  la_left = result[0]['coordinates']['y']\n",
        "  la_right = result[0]['coordinates']['y']\n",
        "  left = 0\n",
        "  right = 9999\n",
        "  result = FindifNull(rets_client, lo_left, lo_right, la_left, la_right, status, date, left, right)\n",
        "  result['FullAddress'] = result['StreetNumber'] + \" \" + result['StreetName']  + \", \" + result['City'] + \", \" +result['StateOrProvince'] + \" \" + result['PostalCode']         \n",
        "  result = result[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt','LotSizeAcres','FullAddress']]\n",
        "\n",
        "  price = []\n",
        "  cdom_signValue = []\n",
        "  df_id = pd.DataFrame()\n",
        "\n",
        "###########################################################\n",
        "# compares\n",
        "    \n",
        "  if(status == 'SLD'): \n",
        "    for item in result['ClosePrice']:\n",
        "      item = float(item)\n",
        "      price.append(item)\n",
        "    result['ClosePrice'] = price\n",
        "    mean1 = result['ClosePrice'].mean()\n",
        "    top1 = list(result['ClosePrice'])\n",
        "    top1.sort(reverse = True)\n",
        "    top1_mean = sum(top1[0:3])/3\n",
        "    min1 = list(result['ClosePrice'])\n",
        "    min1.sort(reverse = False)\n",
        "    median = result['ClosePrice'].median()\n",
        "    percent_mean = (mean1-90)/100 ######\n",
        "    percent_Top_mean = (top1_mean-90)/100######\n",
        "    percent_Top = (top1_mean-90)/100 ######\n",
        "    for item in result['CumulativeDaysOnMarket']:\n",
        "      item = int(item)\n",
        "      cdom_signValue.append(item)\n",
        "    result['CumulativeDaysOnMarket'] = cdom_signValue\n",
        "    cdom = result['CumulativeDaysOnMarket'].mean()\n",
        "    df_id_comp = pd.DataFrame()\n",
        "    df2_append_comp = {'Min': min1[0],'Median': median ,'Mean': mean1,'Top 3 Mean': top1_mean,'Max': top1[0] ,'CDOM': cdom}\n",
        "    df_id_comp = df_id_comp.append(df2_append_comp, ignore_index = True)\n",
        "    df3_append_comp = {'Min': None,'Median': None ,'Mean': percent_mean,'Top 3 Mean': percent_Top_mean,'Max': percent_Top ,'CDOM': None} ######\n",
        "    df_id_comp = df_id_comp.append(df3_append_comp, ignore_index = True)####\n",
        "    df4_append_comp = {'Min': None,'Median': None ,'Mean': 10,'Top 3 Mean': 20,'Max':30 ,'CDOM': None} ######\n",
        "    df_id_comp = df_id_comp.append(df4_append_comp, ignore_index = True)#####\n",
        "    df_id_comp = df_id_comp.rename(index={0: 'Comps', 1: '% above price',2: 'Est. Margin'})#####\n",
        "    df_id_comp.to_csv('{} first.csv'.format(address))\n",
        "###########################################################\n",
        "  df_id_status = pd.DataFrame()\t\t\n",
        "  for i in range(len(result['FullAddress'])):\t\t\t\t\t\t\t\t\n",
        "    df_id_status = df_id_status.append(result.loc[i][column2], ignore_index = True)\n",
        "  return df_id_status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a5tr5Dr_smsa"
      },
      "outputs": [],
      "source": [
        "def judge(i):\n",
        "  #不用管，为了美观\n",
        "    if i % 10 == 1:\n",
        "        return 'st'\n",
        "    elif i % 10 == 2:\n",
        "        return 'nd'\n",
        "    elif i % 10 == 3:\n",
        "        return 'rd'\n",
        "    else:\n",
        "        return 'th'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a_RrPUgWH6yN"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  login_url = 'https://ntrdd.mlsmatrix.com/rets/Login.ashx' \n",
        "  username = '0671181_NID'\n",
        "  password = 'Rt$tg6jx'\n",
        "  rets_client = Session(login_url, username, password)\n",
        "  rets_client.login()\n",
        "  while True:\n",
        "        column2 = ['MlsStatus','FullAddress', 'ListingId', 'ClosePrice', 'LivingArea', 'BedroomsTotal', 'BathroomsTotalInteger', 'YearBuilt', 'GarageSpaces', 'PoolYN', 'LotSizeAcres','CloseDate','CumulativeDaysOnMarket', 'SubdivisionName', 'Longitude', 'Latitude']\n",
        "        print('please insert values, csv_address or csv_mls: ')\n",
        "        choice = input()\n",
        "        if choice == 'csv_address':\n",
        "            while True:\n",
        "                print('select which csv you want to use')\n",
        "                csv = input()\n",
        "                try:\n",
        "                    data = pd.read_csv('{}.csv'.format(csv))        \n",
        "                    code = []\n",
        "                    name = []\n",
        "                    number = []\n",
        "                    street = []\n",
        "                    city = []\n",
        "                    state = []\n",
        "                    for item in data['address']:\n",
        "                        a = item.split(',')[0]\n",
        "                        b = item.split(',')[2]\n",
        "                        c = item.split(',')[1]\n",
        "                        street.append(a)\n",
        "                        city.append(c)\n",
        "                        numbers = a.split()[0]\n",
        "                        names = a.split()[1:(len(a.split()) - 1)]\n",
        "                        codes = b.split()[1][0:5]\n",
        "                        states = b.split()[0]\n",
        "                        state.append(states)\n",
        "                        code.append(codes)\n",
        "                        name.append(names)\n",
        "                        number.append(numbers)\n",
        "                    finalN = []\n",
        "                    for item in name:\n",
        "                        string = \"\"\n",
        "                        for items in item:\n",
        "                            string += items\n",
        "                            string += ' '\n",
        "                        finalN.append(string[0:len(string) - 1])            \n",
        "                    for i in range(len(code)):\n",
        "                        df1 = insertAdd(number[i], finalN[i], city[i], state[i], code[i], street[i], rets_client, column2, \"SLD\", \"2022-01-01-2022-06-30\")\n",
        "                        df2 = insertAdd(number[i], finalN[i], city[i], state[i], code[i], street[i], rets_client, column2, \"PND\", \".EMPTY.\")\n",
        "                        df3 = insertAdd(number[i], finalN[i], city[i], state[i], code[i], street[i], rets_client, column2, \"ACT\", \".EMPTY.\")\n",
        "                        df1.to_csv('{} SLD.csv'.format(finalN[i]))\n",
        "                        #############\n",
        "                        df2 = df2[df2['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                        df2 = df2[df2['Latitude'].between(min(df1['Latitude']),max(df1['Latitude']))]\n",
        "                        #############\n",
        "                        df3 = df3[df3['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                        df3 = df3[df3['Latitude'].between(min(df1['Latitude']),max(df1['Latitude']))]\n",
        "                        frames = [df2, df3]\n",
        "                        df4 = pd.concat(frames, ignore_index=True)\n",
        "                        df4.to_csv('{} PND,ACT.csv'.format(finalN[i]))                        \n",
        "                    return \"finished\"\n",
        "                except FileNotFoundError:\n",
        "                    print(\"Oops! There is no file!  Try again...\")\n",
        "\n",
        "        elif(choice =='csv_mls'):\n",
        "          while True:\n",
        "            print(\"Which csv do you want to use? (make sure you have listingId)\")\n",
        "            csv = input()\n",
        "            try:\n",
        "              lis_mls = []\n",
        "              data = pd.read_csv('{}.csv'.format(csv)) \n",
        "              for item in data['mls']:\n",
        "                lis_mls.append(int(item))\n",
        "              for i in range(len(lis_mls)):\n",
        "                pulled_value = {}\n",
        "                result = rets_client.search(resource='Property', resource_class='Property', dmql_query='(ListingId = {})'.format(lis_mls[i]))\n",
        "                for items in result:\n",
        "                  pulled_value = items\n",
        "                if(len(pulled_value) != 0):\n",
        "                  try:\n",
        "                    df1 = insertId(pulled_value, lis_mls[i], rets_client, column2, \"SLD\", \"2022-01-01-2022-06-30\") \n",
        "                    df2 = insertId(pulled_value, lis_mls[i], rets_client, column2, \"PND\", \".EMPTY.\")\n",
        "                    df3 =  insertId(pulled_value, lis_mls[i], rets_client, column2, \"ACT\", \".EMPTY.\")\n",
        "                    df1.to_csv('{} SLD.csv'.format(lis_mls[i]))\n",
        "                    #############\n",
        "                    df2 = df2[df2['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                    df2 = df2[df2['Latitude'].between(min(df1['Latitude']),max(df1['Latitude']))]\n",
        "                    #############\n",
        "                    df3 = df3[df3['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                    df3 = df3[df3['Latitude'].between(min(df1['Latitude']),max(df1['Latitude']))]\n",
        "                    frames = [df2, df3]\n",
        "                    df4 = pd.concat(frames, ignore_index=True)\n",
        "                    df4.to_csv('{} PND,ACT.csv'.format(lis_mls[i])) \n",
        "                    if i == len(lis_mls) - 1:\n",
        "                        return\n",
        "                  except ValueError:\n",
        "                    print('{} is not valid'.format(lis_mls[i]))\n",
        "                 #end here\n",
        "            except FileNotFoundError:\n",
        "              print(\"Oops! There is no file!  Try again...\")\n",
        "\n",
        "        elif(choice == 'value'):\n",
        "            while True:\n",
        "                print('How many mls you want to check?')\n",
        "                number = input()\n",
        "                try:\n",
        "                    Id_list = []\n",
        "                    for i in range(int(number)):\n",
        "                        print('Enter the {}{} #MLS'.format(i+1, judge(i+1)))\n",
        "                        mls = input()\n",
        "                        Id_list.append(mls)\n",
        "           #14730621\n",
        "                    for i in range(len(Id_list)):\n",
        "                        pulled_value = {}\n",
        "                        result = rets_client.search(resource='Property', resource_class='Property', dmql_query='(ListingId = {})'.format(Id_list[i]))\n",
        "                        for items in result:\n",
        "                            pulled_value = items\n",
        "                        if(len(pulled_value) != 0):\n",
        "                          df1 = insertId(pulled_value, Id_list[i], rets_client, column2, \"SLD\", \"2022-01-01-2022-06-30\") \n",
        "                          df2 = insertId(pulled_value, Id_list[i], rets_client, column2, \"PND\", \".EMPTY.\")\n",
        "                          df3 =  insertId(pulled_value, Id_list[i], rets_client, column2, \"ACT\", \".EMPTY.\")\n",
        "                          df1.to_csv('{} SLD.csv'.format(Id_list[i]))\n",
        "                          #############\n",
        "                          df2 = df2[df2['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                          df2 = df2[df2['Latitude'].between(min(df1['Latitude']),max(df1['Latitude']))]\n",
        "                          #############\n",
        "                          df3 = df3[df3['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                          df3 = df3[df3['Latitude'].between(min(df1['Latitude']),max(df1['Latitude']))]\n",
        "                          frames = [df2, df3]\n",
        "                          df4 = pd.concat(frames, ignore_index=True)\n",
        "                          df4.to_csv('{} PND,ACT.csv'.format(Id_list[i])) \n",
        "                          if(i == len(Id_list) - 1):\n",
        "                              return\n",
        "                        else:\n",
        "\n",
        "                            print('Id {} not exists, please insert specific value'.format(Id_list[i]))\n",
        "                            print(\"If you don't know the address, please insert skip\")\n",
        "                            deci = input()\n",
        "                            if(deci == 'skip'):\n",
        "                                if(i == int(number) - 1):\n",
        "                                    return\n",
        "                                continue\n",
        "                                \n",
        "                            else:\n",
        "                                print('Enter street number')\n",
        "                                number = input()\n",
        "        #'8615 Barclay Street'\n",
        "                                print('Enter street name')\n",
        "                                name = input()\n",
        "                                print('Enter city')\n",
        "                                city = input()\n",
        "        #'Dallas'\n",
        "                                print('Enter state')\n",
        "                                state = input()\n",
        "        #'Texas'\n",
        "                                print('Enter zipcode')\n",
        "                                zip = input()\n",
        "        #'75227'\n",
        "                                string = \"\"\n",
        "                                for i in range(len(name.split()) - 1):\n",
        "                                  string += name.split()[i] + \" \"\n",
        "                                string = string[0:len(string) - 1]\n",
        "                                address = number + ' ' + name\n",
        "                                try:\n",
        "\n",
        "                                  df1 = insertAdd(number, string, city, state, zip, address, rets_client, column2, \"SLD\", \"2022-01-01-2022-06-30\")\n",
        "                                  df2 = insertAdd(number, string, city, state, zip, address, rets_client, column2, \"PND\", \".EMPTY.\")\n",
        "                                  df3 =  insertAdd(number, string, city, state, zip, address, rets_client, column2, \"ACT\", \".EMPTY.\")\n",
        "                                  df1.to_csv('{} SLD.csv'.format(Id_list[i]))\n",
        "                                  df3 = df3[df3['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                                  frames = [df2, df3]\n",
        "                                  df4 = pd.concat(frames, ignore_index=True)\n",
        "                                  df4.to_csv('{} PND,ACT.csv'.format(address)) \n",
        "                                  if(i == int(number) - 1):\n",
        "                                      return\n",
        "                                except IndexError:\n",
        "                                    print(\"invalid input, please next value!\")   \n",
        "\n",
        "                          \n",
        "                except ValueError:\n",
        "                    print(\"invalid input, try again!\")\n",
        "        else:\n",
        "            print(\"invalid input, try again!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "_-lc3ZqLIJRX",
        "outputId": "3131f2aa-9094-4fd6-ebf2-c895b983ae74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "please insert values, csv_address or csv_mls: \n",
            "csv_mls\n",
            "Which csv do you want to use? (make sure you have listingId)\n",
            "June Offer\n",
            "\n",
            "This value exists in Website\n",
            "\n",
            "This value exists in Website\n",
            "\n",
            "This value exists in Website\n",
            "\n",
            "This value exists in Website\n",
            "\n",
            "This value exists in Website\n",
            "\n",
            "This value exists in Website\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ab8285dba5a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#5005 Bama Drive, Arlington, Texas 76017\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-478bad131017>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsertId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpulled_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlis_mls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrets_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SLD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2022-01-01-2022-06-30\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsertId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpulled_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlis_mls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrets_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".EMPTY.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0minsertId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpulled_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlis_mls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrets_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ACT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".EMPTY.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} SLD.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlis_mls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0;31m#############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7b987577b660>\u001b[0m in \u001b[0;36minsertId\u001b[0;34m(pulled_value, mls, rets_client, column2, status, date)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalSqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalYear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mresult1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFindHouse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhouse_leftLa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhouse_rightLa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhouse_leftLo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhouse_rightLo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrets_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mresult1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FullAddress'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StreetNumber'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StreetName'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m\", \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'City'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mresult1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StateOrProvince'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PostalCode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     result1 = result1[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
            "\u001b[0;32m<ipython-input-7-2af5ba39b9fd>\u001b[0m in \u001b[0;36mFindHouse\u001b[0;34m(house_leftLa, house_rightLa, house_leftLo, house_rightLo, research, zip, column, sub, status, date, sq_left, sq_right, begin_year, end_year)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjudgeType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SubdivisionName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rets/session.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, resource, resource_class, search_filter, dmql_query, limit, offset, optional_parameters, auto_offset, query_type, standard_names, response_format)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         response = self._request(\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0mcapability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Search\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         )\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rets/session.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, capability, options, stream)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             response = self.client.post(\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m             )\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \"\"\"\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    585\u001b[0m         }\n\u001b[1;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    497\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m                 )\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(main()) \n",
        "    #5005 Bama Drive, Arlington, Texas 76017"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No Need to Run"
      ],
      "metadata": {
        "id": "pj1cRQN-lptG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H03LHn44G9AS"
      },
      "outputs": [],
      "source": [
        "login_url = 'https://ntrdd.mlsmatrix.com/rets/Login.ashx' \n",
        "username = '0671181_NID'\n",
        "password = 'Rt$tg6jx'\n",
        "rets_client = Session(login_url, username, password)\n",
        "rets_client.login()\n",
        "\n",
        "\n",
        "result = rets_client.search(resource='Property', resource_class='Property', dmql_query='(ListingId = {})'.format(20018438))\n",
        "for item in result:\n",
        "  print(item['PostalCode'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hdvFAW0bEeX"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('test.csv')\n",
        "df.rename(columns={ df.columns[0]: \"地址\" }, inplace = True)\n",
        "df.to_csv('test1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fbd5Dk_FVS1"
      },
      "outputs": [],
      "source": [
        "#df.rename(columns={ df.columns[0]: \"地址\" }, inplace = True)\n",
        "#df.to_csv('test1.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pj1cRQN-lptG"
      ],
      "name": "Rest_Data Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}