{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/penny1xu/RESTS/blob/main/Rest_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJff6UchHVNB",
        "outputId": "94b75e1c-0103-4a52-831e-a319b3c53dbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: censusgeocode in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: requests[security]<3,>=2.27.0 in /usr/local/lib/python3.7/dist-packages (from censusgeocode) (2.28.1)\n",
            "Requirement already satisfied: requests-toolbelt<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from censusgeocode) (0.9.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rets in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: xmltodict>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from rets) (0.13.0)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from rets) (0.16.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from rets) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from rets) (2.28.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install censusgeocode\n",
        "!pip install rets\n",
        "import csv\n",
        "import pandas as pd\n",
        "import censusgeocode as cg\n",
        "import numpy as np\n",
        "import sys\n",
        "from rets import Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "itgrCM-_Lglt"
      },
      "outputs": [],
      "source": [
        "def add(lo_left,lo_right,la_left,la_right):\n",
        "    a = 0.008 #调整经纬度改这里\n",
        "    lo_left -= a\n",
        "    lo_right += a\n",
        "    la_left -= a\n",
        "    la_right += a\n",
        "    return lo_left, lo_right, la_left, la_right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "NtLir-mDWsiX"
      },
      "outputs": [],
      "source": [
        "def judgeType(item):\n",
        "  if(item['PropertyType'] == 'Residential' and item['PropertySubType'] == 'Single Family Residence'):#改type在这里\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "7ltm-qDfls5y"
      },
      "outputs": [],
      "source": [
        "def calSqr(sqr):\n",
        "    if sqr <= 1100:\n",
        "        left = sqr - 100\n",
        "        right = sqr + 100\n",
        "    elif sqr <= 2200:\n",
        "        left = sqr - 200\n",
        "        right = sqr + 200\n",
        "    else:\n",
        "        left = sqr - 300\n",
        "        right = sqr + 300\n",
        "    return left, right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "V9PMU59IqZfn"
      },
      "outputs": [],
      "source": [
        "def calYear(year):\n",
        "  if year < 1990:\n",
        "     begin = 0 \n",
        "     end = 1989\n",
        "  elif year >= 1990 and year < 2011:\n",
        "    begin = 1990\n",
        "    end = 2010\n",
        "  elif year >= 2011 and year < 2022:\n",
        "    begin = 2011\n",
        "    end = 2021\n",
        "  else:\n",
        "    begin = 2022\n",
        "    end = 9999\n",
        "  return begin,end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "j-bVvyh4HrtB"
      },
      "outputs": [],
      "source": [
        "def findifNull(research, lo_left,lo_right,la_left,la_right, bedroom, status, date, sq_left, sq_right,yr_begin,yr_end):\n",
        "  #经纬度查找\n",
        "  bedroom = int(bedroom)\n",
        "  filter = {\n",
        "        \"BathroomsTotalInteger\": \"{}-{}\".format(bedroom - 2, bedroom + 1),\n",
        "        \"BedroomsTotal\": bedroom,\n",
        "        \"Longitude\": \"{}-{}\".format(lo_left, lo_right),\n",
        "        \"Latitude\": \"{}-{}\".format(la_left, la_right),\n",
        "        \"MlsStatus\" : \"{}\".format(status),\n",
        "        \"CloseDate\" : \"{}\".format(date),\n",
        "        \"LivingArea\" : \"{}-{}\".format(sq_left, sq_right),\n",
        "        \"YearBuilt\": \"{}-{}\".format(yr_begin, yr_end)\n",
        "        }\n",
        "  result = research.search(resource='Property', resource_class='Property', search_filter=filter)\n",
        "  lis = []\n",
        "  count = 0\n",
        "  di ={}\n",
        "  df = pd.DataFrame()\n",
        "  for item in result:\n",
        "    if(judgeType(item)):\n",
        "      df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True) #?\n",
        "      count += 1\n",
        "      di = item # 存表头\n",
        "  for key in di:\n",
        "    lis.append(key)\n",
        "  if(count >= 5): \n",
        "    df = df.T\n",
        "    df.columns = lis\n",
        "    return df\n",
        "  else:\n",
        "    lo_left, lo_right, la_left, la_right = add(lo_left,lo_right,la_left,la_right)\n",
        "    return findifNull(research, lo_left,lo_right,la_left,la_right,bedroom, status, date, sq_left, sq_right,yr_begin,yr_end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "BGJv_Nq_Hxuy"
      },
      "outputs": [],
      "source": [
        "def findHouse(house_leftLa,house_rightLa,house_leftLo,house_rightLo,research,zip,column,bedroom, sub, status, date, sq_left, sq_right,yr_begin,yr_end):\n",
        "  #sub，zip查找，未找到足够的自动转经纬度\n",
        "  filter = {\n",
        "        \"BathroomsTotalInteger\": \"{}-{}\".format(bedroom - 2, bedroom + 1),\n",
        "        \"BedroomsTotal\": bedroom,\n",
        "        \"PostalCode\" : zip,\n",
        "        \"MlsStatus\" : \"{}\".format(status),\n",
        "        \"CloseDate\" : \"{}\".format(date),\n",
        "        \"LivingArea\" : \"{}-{}\".format(sq_left, sq_right),\n",
        "        \"YearBuilt\": \"{}-{}\".format(yr_begin, yr_end)\n",
        "        }\n",
        "  result = research.search(resource='Property', resource_class='Property', search_filter=filter)\n",
        "  count = 0\n",
        "  df = pd.DataFrame()\n",
        "  for item in result: \n",
        "    if(judgeType(item)):\n",
        "      if(sub == item['SubdivisionName'].lower().split()[0]):\n",
        "         df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True) #?\n",
        "         count += 1    \n",
        "  if(count >= 5):  \n",
        "    df = df.T\n",
        "    df.columns = column # \n",
        "    return df\n",
        "  else:\n",
        "    return findifNull(research, house_leftLo,house_rightLo, house_leftLa, house_rightLa, bedroom, status, date, sq_left, sq_right,yr_begin,yr_end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "FdyoCacQ9qP_"
      },
      "outputs": [],
      "source": [
        "def findfirst(result):\n",
        "  #判断是否有，不用管\n",
        "    count = 0\n",
        "    for item in result:\n",
        "        count += 1\n",
        "    if(count == 0):\n",
        "        return False\n",
        "    else:\n",
        "        return True    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "QiyDiActQzMq"
      },
      "outputs": [],
      "source": [
        "def insertId(pulled_value, mls,rets_client, column2, status, date):\n",
        "  #mls查找，按照先sub + zip，后geo\n",
        "  column = []\n",
        "  for key in pulled_value:\n",
        "    column.append(key)\n",
        "  print(\"\\nThis value exists in Website\")\n",
        "  zip = pulled_value.get('PostalCode')\n",
        "  latitude = pulled_value.get('Latitude')\n",
        "  longitude = pulled_value.get('Longitude')\n",
        "  bedroom = pulled_value.get('BedroomsTotal')\n",
        "  sqr = pulled_value.get('LivingArea')\n",
        "  name = pulled_value.get('StreetName')\n",
        "  number = pulled_value.get('StreetNumber')\n",
        "  city = pulled_value.get('City')\n",
        "  state = pulled_value.get('StateOrProvince')\n",
        "  year = pulled_value.get('YearBuilt')\n",
        "  self_price1 = float(pulled_value.get('ClosePrice'))\n",
        "  if(zip != \"\" and latitude != \"\" and longitude != \"\" and bedroom != \"\" and sqr != \"\" and year != \"\"):\n",
        "    #findAdd(rets_client, address, city, state, zipcode, bedroom, status, date, column2)\n",
        "    if(int(bedroom) >= 3 and int(bedroom) <= 5):\n",
        "      house_leftLa = float(pulled_value.get('Latitude'))\n",
        "      house_rightLa = float(pulled_value.get('Latitude')) \n",
        "      house_leftLo = float(pulled_value.get('Longitude'))\n",
        "      house_rightLo = float(pulled_value.get('Longitude'))\n",
        "      sub = str(pulled_value.get('SubdivisionName').lower().split()[0])\n",
        "      sqr = float(sqr)\n",
        "      year = int(year)\n",
        "      left, right = calSqr(sqr)\n",
        "      begin,end = calYear(year)\n",
        "      result1 = findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, rets_client,int(zip) ,column,int(bedroom), sub, status, date, left, right,begin,end) \n",
        "      result1['FullAddress'] = result1['StreetNumber'] + \" \" + result1['StreetName']  + \", \" + result1['City'] + \", \" +result1['StateOrProvince'] + \" \" + result1['PostalCode']       \n",
        "      result1 = result1[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt','LotSizeAcres','FullAddress']]\n",
        "      price = []\n",
        "      cdom_signValue = []\n",
        "      df_id = pd.DataFrame()\n",
        "\n",
        "###########################################################\n",
        "# compares\n",
        "      \n",
        "      if(status == 'SLD'): \n",
        "        for item in result1['ClosePrice']:\n",
        "          item = float(item)\n",
        "          price.append(item)\n",
        "        result1['ClosePrice'] = price\n",
        "        mean1 = result1['ClosePrice'].mean()\n",
        "        top1 = list(result1['ClosePrice'])\n",
        "        top1.sort(reverse = True)\n",
        "        top1_mean = sum(top1[0:3])/3\n",
        "        min1 = list(result1['ClosePrice'])\n",
        "        min1.sort(reverse = False)\n",
        "        median = result1['ClosePrice'].median()\n",
        "        percent_mean1 = ((mean1 - self_price1)/ self_price1)*100 ######\n",
        "        percent_Top_mean1 = ((top1_mean - self_price1)/self_price1)*100 ######\n",
        "        percent_Top1 = ((top1_mean - self_price1)/self_price1)*100 ######\n",
        "        for item in result1['CumulativeDaysOnMarket']:\n",
        "          item = int(item)\n",
        "          cdom_signValue.append(item)\n",
        "        result1['CumulativeDaysOnMarket'] = cdom_signValue\n",
        "        cdom = result1['CumulativeDaysOnMarket'].mean()\n",
        "        df_id_comp = pd.DataFrame()\n",
        "        df2_append_comp = {'Min': min1[0],'Median': median ,'Mean': mean1,'Top 3 Mean': top1_mean,'Max': top1[0] ,'CDOM': cdom}\n",
        "        df_id_comp = df_id_comp.append(df2_append_comp, ignore_index = True)\n",
        "        df3_append_comp = {'Min': None,'Median': None ,'Mean': percent_mean1,'Top 3 Mean': percent_Top_mean1,'Max': percent_Top1 ,'CDOM': None} ######\n",
        "        df_id_comp = df_id_comp.append(df3_append_comp, ignore_index = True)####\n",
        "        df4_append_comp = {'Min': None,'Median': None ,'Mean': 10,'Top 3 Mean': 20,'Max':30 ,'CDOM': None} ######\n",
        "        df_id_comp = df_id_comp.append(df4_append_comp, ignore_index = True)#####\n",
        "        df_id_comp = df_id_comp.rename(index={0: 'Comps', 1: '% above price',2: 'Est. Margin'})#####\n",
        "        df_id_comp.to_csv('{}.csv'.format(mls))\n",
        "###########################################################\n",
        "      df_id_status = pd.DataFrame()\t\t\n",
        "      for i in range(len(result1['FullAddress'])):\t\t\t\t\t\t\t\t\n",
        "        df_id_status = df_id_status.append(result1.loc[i][column2], ignore_index = True)\n",
        "      return df_id_status\n",
        "    else:\n",
        "      print(\"Bedroom number is not qualified\")\n",
        "      return\n",
        "  elif(zip != \"\" and city != \"\" and name != \"\" and number != \"\" and state != \"\"):\n",
        "    address = number + ' ' + name\n",
        "    bedroom = 3\n",
        "    print(address, city, state, zip)\n",
        "    return findAdd(rets_client, address, city, state, int(zip), bedroom, status, date, column2)\n",
        "  else:\n",
        "    print('Information missing in the system!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "ljfKnnerAJjw"
      },
      "outputs": [],
      "source": [
        "def insertAdd(number, name, city, state, zip, address, rets_client, column2, status, date):\n",
        "  #add查找，按照先sub + zip，后geo\n",
        "  pulled_value = {}\n",
        "  result = rets_client.search(resource = 'Property', resource_class='Property', dmql_query='(StreetNumber = {}),(StreetName = {}),(PostalCode = {})'.format(number,name,zip))\n",
        "  for item in result:\n",
        "    pulled_value = item\n",
        "  if(len(pulled_value) != 0):\n",
        "    column = []\n",
        "    for key in pulled_value:\n",
        "      column.append(key)\n",
        "    print(\"\\nThis value exists in Website\")\n",
        "    zip = pulled_value.get('PostalCode')\n",
        "    latitude = pulled_value.get('Latitude')\n",
        "    longitude = pulled_value.get('Longitude')\n",
        "    bedroom = pulled_value.get('BedroomsTotal')\n",
        "    sqr = pulled_value.get('LivingArea')\n",
        "    year = pulled_value.get('YearBuilt')\n",
        "    self_price1 = float(pulled_value.get('ClosePrice'))\n",
        "    if(zip != \"\" and latitude != \"\" and longitude != \"\" and bedroom != \"\" and sqr != \"\" and year !=\"\"):\n",
        "      if(int(bedroom) >= 3 and int(bedroom) <= 5):\n",
        "        house_leftLa = float(pulled_value.get('Latitude'))\n",
        "        house_rightLa = float(pulled_value.get('Latitude')) \n",
        "        house_leftLo = float(pulled_value.get('Longitude'))\n",
        "        house_rightLo = float(pulled_value.get('Longitude'))\n",
        "        zip = int(pulled_value.get('PostalCode'))\n",
        "        sqr = float(sqr)\n",
        "        year = int(year)\n",
        "        left, right = calSqr(sqr)\n",
        "        begin, end = calYear(year)\n",
        "        sub = str(pulled_value.get('SubdivisionName').lower().split()[0])\n",
        "        result1 = findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, rets_client,zip,column,int(bedroom), sub, status, date, left, right,begin,end)        \n",
        "        result1['FullAddress'] = result1['StreetNumber'] + \" \" + result1['StreetName']  + \", \" + result1['City'] + \", \" +result1['StateOrProvince'] + \" \" + result1['PostalCode']       \n",
        "        result1 = result1[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt','LotSizeAcres','FullAddress']]\n",
        "        price = []\n",
        "        cdom_signValue = []\n",
        "        df_id = pd.DataFrame()\n",
        "###########################################################\n",
        "# compares\n",
        "    \n",
        "        if(status == 'SLD'): \n",
        "          for item in result1['ClosePrice']:\n",
        "            item = float(item)\n",
        "            price.append(item)\n",
        "          result1['ClosePrice'] = price\n",
        "          mean1 = result1['ClosePrice'].mean()\n",
        "          top1 = list(result1['ClosePrice'])\n",
        "          top1.sort(reverse = True)\n",
        "          top1_mean = sum(top1[0:3])/3\n",
        "          min1 = list(result1['ClosePrice'])\n",
        "          min1.sort(reverse = False)\n",
        "          percent_mean1 = ((mean1 - self_price1)/ self_price1)*100 ######\n",
        "          percent_Top_mean1 = ((top1_mean - self_price1)/self_price1)*100 ######\n",
        "          percent_Top1 = ((top1_mean - self_price1)/self_price1)*100 ######\n",
        "          median = result1['ClosePrice'].median()\n",
        "          for item in result1['CumulativeDaysOnMarket']:\n",
        "            item = int(item)\n",
        "            cdom_signValue.append(item)\n",
        "          result1['CumulativeDaysOnMarket'] = cdom_signValue\n",
        "          cdom = result1['CumulativeDaysOnMarket'].mean()\n",
        "          df_id_comp = pd.DataFrame()\n",
        "          df2_append_comp = {'Min': min1[0],'Median': median ,'Mean': mean1,'Top 3 Mean': top1_mean,'Max': top1[0] ,'Avg. CDOM': cdom}\n",
        "          df_id_comp = df_id_comp.append(df2_append_comp, ignore_index = True)\n",
        "          df3_append_comp = {'Min': None,'Median': None ,'Mean': percent_mean1,'Top 3 Mean': percent_Top_mean1,'Max': percent_Top1 ,'CDOM': None} ######\n",
        "          df_id_comp = df_id_comp.append(df3_append_comp, ignore_index = True)####\n",
        "          df4_append_comp = {'Min': None,'Median': None ,'Mean': 10,'Top 3 Mean': 20,'Max':30 ,'CDOM': None} ######\n",
        "          df_id_comp = df_id_comp.append(df4_append_comp, ignore_index = True)#####\n",
        "          df_id_comp = df_id_comp.rename(index={0: 'Comps', 1: '% above price',2: 'Est. Margin'})#####\n",
        "          df_id_comp.to_csv('{}.csv'.format(address))\n",
        "###########################################################\n",
        "        df_id_status = pd.DataFrame()\t\t\n",
        "        for i in range(len(result1['FullAddress'])):\t\t\t\t\t\t\t\t\n",
        "          df_id_status = df_id_status.append(result1.loc[i][column2], ignore_index = True)\n",
        "        return df_id_status\n",
        "      else:\n",
        "        print(\"Bedroom number is not qualified\")\n",
        "        return\n",
        "    else:\n",
        "      print('check coordinates')\n",
        "      bedroom = 3\n",
        "      return findAdd(rets_client, address, city, state, zip, bedroom, status, date, column2)\n",
        "  else:\n",
        "    print('check coordinates')\n",
        "    bedroom = 3\n",
        "    return findAdd(rets_client, address, city, state, zip, bedroom, status, date, column2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "F7MCZWuKUJN-"
      },
      "outputs": [],
      "source": [
        "def findAdd(rets_client, address, city, state, zipcode, bedroom, status, date, column2):  \n",
        "  #geo代码，在mls和address中引用\n",
        "  result = cg.address(address, city = city, state= state,zipcode = zipcode)\n",
        "  lo_left = result[0]['coordinates']['x']\n",
        "  lo_right = result[0]['coordinates']['x']\n",
        "  la_left = result[0]['coordinates']['y']\n",
        "  la_right = result[0]['coordinates']['y']\n",
        "  left = 0\n",
        "  right = 9999\n",
        "  begin = 0\n",
        "  end = 9999\n",
        "\n",
        "  result = findifNull(rets_client, lo_left, lo_right, la_left, la_right, bedroom, status, date, left, right, begin, end)\n",
        "  result['FullAddress'] = result['StreetNumber'] + \" \" + result['StreetName']  + \", \" + result['City'] + \", \" +result['StateOrProvince'] + \" \" + result['PostalCode']         \n",
        "  result = result[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt','LotSizeAcres','FullAddress']]\n",
        "\n",
        "  price = []\n",
        "  cdom_signValue = []\n",
        "  df_id = pd.DataFrame()\n",
        "\n",
        "\n",
        "###########################################################\n",
        "# compares\n",
        "    \n",
        "  if(status == 'SLD'): \n",
        "    for item in result['ClosePrice']:\n",
        "      item = float(item)\n",
        "      price.append(item)\n",
        "    result['ClosePrice'] = price\n",
        "    mean1 = result['ClosePrice'].mean()\n",
        "    top1 = list(result['ClosePrice'])\n",
        "    top1.sort(reverse = True)\n",
        "    top1_mean = sum(top1[0:3])/3\n",
        "    min1 = list(result['ClosePrice'])\n",
        "    min1.sort(reverse = False)\n",
        "    median = result['ClosePrice'].median()\n",
        "    percent_mean1 = ((mean1 - 90)/ 100)*100 ######\n",
        "    percent_Top_mean1 = ((top1_mean - 90)/100)*100 ######\n",
        "    percent_Top1 = ((top1_mean - 90)/100)*100 ######\n",
        "    for item in result['CumulativeDaysOnMarket']:\n",
        "      item = int(item)\n",
        "      cdom_signValue.append(item)\n",
        "    result['CumulativeDaysOnMarket'] = cdom_signValue\n",
        "    cdom = result['CumulativeDaysOnMarket'].mean()\n",
        "    df_id_comp = pd.DataFrame()\n",
        "    df2_append_comp = {'Min': min1[0],'Median': median ,'Mean': mean1,'Top 3 Mean': top1_mean,'Max': top1[0] ,'CDOM': cdom}\n",
        "    df_id_comp = df_id_comp.append(df2_append_comp, ignore_index = True)\n",
        "    df3_append_comp = {'Min': None,'Median': None ,'Mean': percent_mean1,'Top 3 Mean': percent_Top_mean1,'Max': percent_Top1 ,'CDOM': None} ######\n",
        "    df_id_comp = df_id_comp.append(df3_append_comp, ignore_index = True)####\n",
        "    df4_append_comp = {'Min': None,'Median': None ,'Mean': 10,'Top 3 Mean': 20,'Max':30 ,'CDOM': None} ######\n",
        "    df_id_comp = df_id_comp.append(df4_append_comp, ignore_index = True)#####\n",
        "    df_id_comp = df_id_comp.rename(index={0: 'Comps', 1: '% above price',2: 'Est. Margin'})#####\n",
        "    df_id_comp.to_csv('{} first.csv'.format(address))\n",
        "###########################################################\n",
        "  df_id_status = pd.DataFrame()\t\t\n",
        "  for i in range(len(result['FullAddress'])):\t\t\t\t\t\t\t\t\n",
        "    df_id_status = df_id_status.append(result.loc[i][column2], ignore_index = True)\n",
        "  return df_id_status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "a5tr5Dr_smsa"
      },
      "outputs": [],
      "source": [
        "def judge(i):\n",
        "  #不用管，为了美观\n",
        "    if i % 10 == 1:\n",
        "        return 'st'\n",
        "    elif i % 10 == 2:\n",
        "        return 'nd'\n",
        "    elif i % 10 == 3:\n",
        "        return 'rd'\n",
        "    else:\n",
        "        return 'th'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "a_RrPUgWH6yN"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  login_url = 'https://ntrdd.mlsmatrix.com/rets/Login.ashx' \n",
        "  username = '0671181_NID'\n",
        "  password = 'Rt$tg6jx'\n",
        "  rets_client = Session(login_url, username, password)\n",
        "  rets_client.login()\n",
        "  while True:\n",
        "        column2 = ['MlsStatus','FullAddress', 'ListingId', 'ListPrice', 'LivingArea', 'BedroomsTotal', 'BathroomsTotalInteger', 'YearBuilt', 'GarageSpaces', 'PoolYN', 'LotSizeAcres','CloseDate','CumulativeDaysOnMarket', 'SubdivisionName', 'Longitude', 'Latitude']\n",
        "        print('please insert values, csv_address or csv_mls: ')\n",
        "        choice = input()\n",
        "        if choice == 'csv_address':\n",
        "            while True:\n",
        "                print('select which csv you want to use')\n",
        "                csv = input()\n",
        "                try:\n",
        "                    data = pd.read_csv('{}.csv'.format(csv))        \n",
        "                    code = []\n",
        "                    name = []\n",
        "                    number = []\n",
        "                    street = []\n",
        "                    city = []\n",
        "                    state = []\n",
        "                    for item in data['address']:\n",
        "                        a = item.split(',')[0]\n",
        "                        b = item.split(',')[2]\n",
        "                        c = item.split(',')[1]\n",
        "                        street.append(a)\n",
        "                        city.append(c)\n",
        "                        numbers = a.split()[0]\n",
        "                        names = a.split()[1:(len(a.split()) - 1)]\n",
        "                        codes = b.split()[1][0:5]\n",
        "                        states = b.split()[0]\n",
        "                        state.append(states)\n",
        "                        code.append(codes)\n",
        "                        name.append(names)\n",
        "                        number.append(numbers)\n",
        "                    finalN = []\n",
        "                    for item in name:\n",
        "                        string = \"\"\n",
        "                        for items in item:\n",
        "                            string += items\n",
        "                            string += ' '\n",
        "                        finalN.append(string[0:len(string) - 1])            \n",
        "                    for i in range(len(code)):\n",
        "                      try:\n",
        "                        df1 = insertAdd(number[i], finalN[i], city[i], state[i], code[i], street[i], rets_client, column2, \"SLD\", \"2022-01-01-2022-06-30\")\n",
        "                        df2 = insertAdd(number[i], finalN[i], city[i], state[i], code[i], street[i], rets_client, column2, \"PND\", \".EMPTY.\")\n",
        "                        df3 = insertAdd(number[i], finalN[i], city[i], state[i], code[i], street[i], rets_client, column2, \"ACT\", \".EMPTY.\")\n",
        "                        df1.to_csv('{} SLD.csv'.format(finalN[i]))\n",
        "                        #############\n",
        "                        df2 = df2[df2['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                        df2 = df2[df2['Latitude'].between(min(df1['Latitude']),max(df1['Latitude']))]\n",
        "                        #############\n",
        "                        df3 = df3[df3['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                        df3 = df3[df3['Latitude'].between(min(df1['Latitude']),max(df1['Latitude']))]\n",
        "                        frames = [df2, df3]\n",
        "                        df4 = pd.concat(frames, ignore_index=True)\n",
        "                        df4.to_csv('{} PND,ACT.csv'.format(finalN[i]))\n",
        "                      except AttributeError and IndexError:\n",
        "                        print(\"{} is not exist!\".format(finalN[i]))                       \n",
        "                    return \"finished\"\n",
        "                except FileNotFoundError:\n",
        "                    print(\"Oops! There is no file!  Try again...\")\n",
        "\n",
        "        elif(choice =='csv_mls'):\n",
        "          while True:\n",
        "            print(\"Which csv do you want to use? (make sure you have listingId)\")\n",
        "            csv = input()\n",
        "            try:\n",
        "              lis_mls = []\n",
        "              data = pd.read_csv('{}.csv'.format(csv)) \n",
        "              for item in data['ListingId']:\n",
        "                lis_mls.append(int(item))\n",
        "              for i in range(len(lis_mls)):\n",
        "                pulled_value = {}\n",
        "                result = rets_client.search(resource='Property', resource_class='Property', dmql_query='(ListingId = {})'.format(lis_mls[i]))\n",
        "                for items in result:\n",
        "                  pulled_value = items\n",
        "                if(len(pulled_value) != 0):\n",
        "                  try:\n",
        "                    df1 = insertId(pulled_value, lis_mls[i], rets_client, column2, \"SLD\", \"2022-01-01-2022-06-30\") \n",
        "                    df2 = insertId(pulled_value, lis_mls[i], rets_client, column2, \"PND\", \".EMPTY.\")\n",
        "                    df3 =  insertId(pulled_value, lis_mls[i], rets_client, column2, \"ACT\", \".EMPTY.\")\n",
        "                    df1.to_csv('{} SLD.csv'.format(lis_mls[i]))\n",
        "                    #############\n",
        "                    df2 = df2[df2['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                    df2 = df2[df2['Latitude'].between(min(df1['Latitude']),max(df1['Latitude']))]\n",
        "                    #############\n",
        "                    df3 = df3[df3['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                    df3 = df3[df3['Latitude'].between(min(df1['Latitude']),max(df1['Latitude']))]\n",
        "                    frames = [df2, df3]\n",
        "                    df4 = pd.concat(frames, ignore_index=True)\n",
        "                    df4.to_csv('{} PND,ACT.csv'.format(lis_mls[i])) \n",
        "                    if i == len(lis_mls) - 1:\n",
        "                        return\n",
        "                  except AttributeError and IndexError:\n",
        "                     print('{} is not valid'.format(lis_mls[i]))\n",
        "                 #end here\n",
        "            except FileNotFoundError:\n",
        "              print(\"Oops! There is no file!  Try again...\")\n",
        "\n",
        "        elif(choice == 'value'):\n",
        "            while True:\n",
        "                print('How many mls you want to check?')\n",
        "                number = input()\n",
        "                try: ###\n",
        "                    Id_list = []\n",
        "                    for i in range(int(number)):\n",
        "                        print('Enter the {}{} #MLS'.format(i+1, judge(i+1)))\n",
        "                        mls = input()\n",
        "                        Id_list.append(mls)\n",
        "                        \n",
        "           #14730621\n",
        "                    for i in range(len(Id_list)):\n",
        "                        pulled_value = {}\n",
        "                        result = rets_client.search(resource='Property', resource_class='Property', dmql_query='(ListingId = {})'.format(Id_list[i]))\n",
        "                        for items in result:\n",
        "                            pulled_value = items\n",
        "                            print(items)\n",
        "                        if(len(pulled_value) != 0):\n",
        "                          try:\n",
        "                            df1 = insertId(pulled_value, Id_list[i], rets_client, column2, \"SLD\", \"2022-01-01-2022-06-30\") \n",
        "                            df2 = insertId(pulled_value, Id_list[i], rets_client, column2, \"PND\", \".EMPTY.\")\n",
        "                            df3 =  insertId(pulled_value, Id_list[i], rets_client, column2, \"ACT\", \".EMPTY.\")\n",
        "                            df1.to_csv('{} SLD.csv'.format(Id_list[i]))\n",
        "                          #############\n",
        "                            df2 = df2[df2['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                            df2 = df2[df2['Latitude'].between(min(df1['Latitude']),max(df1['Latitude']))]\n",
        "                          #############\n",
        "                            df3 = df3[df3['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                            df3 = df3[df3['Latitude'].between(min(df1['Latitude']),max(df1['Latitude']))]\n",
        "                            frames = [df2, df3]\n",
        "                            df4 = pd.concat(frames, ignore_index=True)\n",
        "                            df4.to_csv('{} PND,ACT.csv'.format(Id_list[i])) \n",
        "                          except AttributeError and IndexError:\n",
        "                            print(\"{} is not exist!\".format(Id_list[i]))\n",
        "                          if(i == len(Id_list) - 1):\n",
        "                              return\n",
        "                        else:\n",
        "\n",
        "                            print('Id {} not exists, please insert specific value'.format(Id_list[i]))\n",
        "                            print(\"If you don't know the address, please insert skip\")\n",
        "                            deci = input()\n",
        "                            if(deci == 'skip'):\n",
        "                                if(i == int(number) - 1):\n",
        "                                    return\n",
        "                                continue\n",
        "                                \n",
        "                            else:\n",
        "                                print('Enter street number')\n",
        "                                number = input()\n",
        "        #'8615 Barclay Street'\n",
        "                                print('Enter street name')\n",
        "                                name = input()\n",
        "                                print('Enter city')\n",
        "                                city = input()\n",
        "        #'Dallas'\n",
        "                                print('Enter state')\n",
        "                                state = input()\n",
        "        #'Texas'\n",
        "                                print('Enter zipcode')\n",
        "                                zip = input()\n",
        "        #'75227'\n",
        "                                string = \"\"\n",
        "                                for i in range(len(name.split()) - 1):\n",
        "                                  string += name.split()[i] + \" \"\n",
        "                                string = string[0:len(string) - 1]\n",
        "                                address = number + ' ' + name\n",
        "                                try:\n",
        "\n",
        "                                  df1 = insertAdd(number, string, city, state, zip, address, rets_client, column2, \"SLD\", \"2022-01-01-2022-06-30\")\n",
        "                                  df2 = insertAdd(number, string, city, state, zip, address, rets_client, column2, \"PND\", \".EMPTY.\")\n",
        "                                  df3 =  insertAdd(number, string, city, state, zip, address, rets_client, column2, \"ACT\", \".EMPTY.\")\n",
        "                                  df1.to_csv('{} SLD.csv'.format(Id_list[i]))\n",
        "                                  df3 = df3[df3['Longitude'].between(min(df1['Longitude']),max(df1['Longitude']))]\n",
        "                                  frames = [df2, df3]\n",
        "                                  df4 = pd.concat(frames, ignore_index=True)\n",
        "                                  df4.to_csv('{} PND,ACT.csv'.format(address)) \n",
        "                                  if(i == int(number) - 1):\n",
        "                                      return\n",
        "                                except AttributeError and IndexError:\n",
        "                                    print(\"{} is not exist!\".format(address))   \n",
        "\n",
        "                         \n",
        "                except ValueError:\n",
        "                    print(\"invalid input1, try again!\")\n",
        "        else:\n",
        "            print(\"invalid input, try again!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-lc3ZqLIJRX",
        "outputId": "01a5f508-c2a8-4c2e-ee4f-af55b732a4a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "please insert values, csv_address or csv_mls: \n",
            "value\n",
            "How many mls you want to check?\n",
            "1\n",
            "Enter the 1st #MLS\n",
            "20012516\n",
            "{'ListingKeyNumeric': '414325288', 'BathroomsFull': '2', 'BathroomsHalf': '0', 'BathroomsTotalInteger': '2', 'BedroomsTotal': '3', 'BuildingAreaSource': '', 'BuildingAreaTotal': '', 'BuyerAgencyCompensation': '2.5', 'BuyerAgencyCompensationType': '%', 'BuyerAgentDirectPhone': '702-806-7899', 'BuyerAgentEmail': 'ebrinkley33@gmail.com', 'BuyerAgentFullName': 'Eric Brinkley Jr.', 'BuyerAgentKeyNumeric': '68054046', 'BuyerAgentMlsId': '0684565', 'BuyerOfficeKeyNumeric': '15514786', 'BuyerOfficeMlsId': 'XPTY01', 'BuyerOfficeName': 'eXp Realty LLC', 'BuyerOfficePhone': '888-519-7431', 'CancellationDate': '', 'City': 'Mesquite', 'CloseDate': '2022-05-09', 'ClosePrice': '265000.00', 'CoBuyerAgentDirectPhone': '', 'CoBuyerAgentEmail': '', 'CoBuyerAgentFullName': '', 'CoBuyerAgentKeyNumeric': '', 'CoBuyerAgentMlsId': '', 'CoBuyerOfficeKeyNumeric': '', 'CoBuyerOfficeMlsId': '', 'CoBuyerOfficeName': '', 'CoBuyerOfficePhone': '', 'CoListAgentDirectPhone': '', 'CoListAgentEmail': '', 'CoListAgentFullName': '', 'CoListAgentKeyNumeric': '', 'CoListAgentMlsId': '', 'CoListOfficeKeyNumeric': '', 'CoListOfficeMlsId': '', 'CoListOfficeName': '', 'CoListOfficePhone': '', 'Cooling': 'Central Air,Electric', 'CountyOrParish': 'Dallas', 'CumulativeDaysOnMarket': '16', 'DaysOnMarket': '16', 'Directions': 'Perfect location! Very close to major highways of 635 and I30. Minutes to Eastfield College. Near various restaurants and the shopping malls. Follow the GPS', 'Heating': 'Central,Fireplace(s),Gas Jets', 'InternetAddressDisplayYN': '1', 'InternetAutomatedValuationDisplayYN': '1', 'InternetConsumerCommentYN': '1', 'InternetEntireListingDisplayYN': '1', 'Latitude': '32.81495400', 'ListAgentDirectPhone': '626-679-6285', 'ListAgentEmail': 'nyichaowang@gmail.com', 'ListAgentFullName': 'Yichao Wang', 'ListAgentKeyNumeric': '157025420', 'ListAgentMlsId': '0761112', 'ListingAgreement': 'Exclusive Right To Sell', 'ListingContractDate': '2022-03-18', 'ListingId': '20012516', 'ListingService': '', 'ListOfficeKeyNumeric': '126229936', 'ListOfficeMlsId': 'UPROP01C', 'ListOfficeName': 'U Property Management', 'ListOfficePhone': '214-407-8907', 'ListPrice': '259900.00', 'LivingArea': '1606.00', 'Longitude': '-96.65156600', 'MlsStatus': 'Closed', 'ModificationTimestamp': '2022-05-10T00:46:33.740', 'OffMarketDate': '2022-04-05', 'OriginalListPrice': '259900.00', 'OriginatingSystemName': 'North Texas Real Estate Information Systems', 'ParcelNumber': '38033500130280000', 'PhotosChangeTimestamp': '2022-03-29T22:16:44.270', 'PhotosCount': '15', 'PostalCode': '75150', 'PostalCodePlus4': '2134', 'PreviousListPrice': '', 'PriceChangeTimestamp': '', 'PrivateRemarks': \"Seller doesn't have a survey, buyer needs to order one on his or her own. For all question and inquiries, please contact transaction coordinator Lucas at (323)-529-7287 and csiwei0731@icloud.com. ALL OFFERS MUST SUBMIT TO csiwei0731@icloud.com! Buyer or Buyer's Agent to verify measurements, schools, & tax, etc. For all offers.\", 'PropertySubType': 'Single Family Residence', 'PropertyType': 'Residential', 'PublicRemarks': 'Multiple offers received, highest and best due on 4.3.2022 at 8pm. Fully Renovated! Move in ready. Welcome to this elegant sweet 3b2b home located in HIGHLY desirable Casa View area with contemporary interior design. The huge living area inviting positive vibes & offering open space making entertaining a breeze. Create lasting memories in your oversized backyard. Two shad will bring extra storage sapce as well. Come & check out this hidden gem with all design details, high-end material & hidden features! Renovations include brand new kitchen stainless steel appliances with 1 year warranty, upgraded kitchen with high-end granite countertop and upgraded bathrooms with new toilets and granite counter top vanities, all new light fixtures, flooring covered with luxury vinyl plank & fresh new paint throughout interior. This is the HOME that you deserve! Make this home YOURS NOW!', 'PurchaseContractDate': '2022-04-05', 'StandardStatus': 'Closed', 'StateOrProvince': 'Texas', 'StatusChangeTimestamp': '2022-05-10T00:46:33.740', 'StoriesTotal': '', 'StreetDirPrefix': '', 'StreetDirSuffix': '', 'StreetName': 'Ruby', 'StreetNumber': '3505', 'StreetNumberNumeric': '3505', 'StreetSuffix': 'Drive', 'SyndicateTo': 'Homes.com,Members IDX Websites,NTREIS Translator,Realtor.com,Realtors Property Resource,Syndicate Listing', 'UnitNumber': '', 'WithdrawnDate': '', 'YearBuilt': '1958', 'PreviousStatus': 'Pending', 'SpecialListingConditions': 'Standard', 'AccessibilityFeatures': '', 'AccessibilityFeaturesYN': '0', 'AccessoryUnitSF': '', 'AccessoryUnitType': '', 'AccessoryUnitYN': '0', 'AcresBottomLand': '', 'AcresCultivated': '', 'AcresIrrigated': '', 'AcresPasture': '', 'AerialPhotoAvailableYN': '', 'AGExemptionYN': '', 'AppFeePayableTo': '', 'AppFeePlus18YrsYN': '', 'AppliancesYN': '', 'Appliances': 'Dishwasher,Disposal,Gas Range', 'ApplicationFeeAmount': '', 'ApplicationFeeYN': '', 'AppraiserName': '', 'ArchitecturalStyle': 'Traditional', 'AssociationFee': '', 'AssociationFeeFrequency': '', 'AssociationFeeIncludes': '', 'AssociationType': 'None', 'AttachedGarageYN': '0', 'AuctionYN': '', 'AvailabilityDate': '', 'AverageMonthlyLease': '', 'OnMarketDate': '', 'HorseAmenities': '', 'BasementYN': '0', 'BathroomsTotalDecimal': '2.00', 'BuildingNumber': '', 'BuildingUse': '', 'BusinessName': '', 'BusinessType': '', 'BuyerFinancing': 'Conventional', 'BuyerTeamKey': '', 'BuyerTeamKeyNumeric': '', 'BuyerTeamName': '', 'CapitalizationRate': '', 'CarportSpaces': '0', 'CeilingHeight': '', 'CommercialFeatures': '', 'CommunityFeatures': '', 'CompensationPaid': '', 'ComplexName': '', 'ConsentforVisitorstoRecord': 'None', 'ConstructionMaterials': 'Brick,Wood', 'ContingencyInfo': '', 'Country': 'United States', 'CoveredSpaces': '0', 'CropRetireProgramYN': '', 'Crops': '', 'CurrentUse': '', 'DepositAmount': '', 'DepositPet': '', 'DevelopmentStatus': '', 'DOCBOX_GUID': '53612299-1C16-48C3-AA9C-A98C6C7948EF', 'DocBox_ModificationTimestamp': '2022-03-23T22:55:06.450', 'DocBox_NumMlsDocuments': '1', 'DocBox_NumPrivateDocuments': '0', 'DocBox_NumPublicDocuments': '0', 'DockPermittedYN': '0', 'DocumentManagerMLSCount': '', 'DocumentManagerPrivateCount': '', 'DocumentManagerPublicCount': '', 'DocumentManagerTotalCount': '', 'DocumentsAvailable': '', 'DualVariableCompensationYN': '0', 'Easements': 'None', 'ElementarySchool': '', 'ElementarySchoolName': 'Lawrence', 'EnergySavingFeatures': '', 'Exclusions': '', 'ExpirationDateOption': '', 'ExteriorFeatures': '', 'FarmRanchFeatures': '', 'Fencing': 'Metal', 'FHA_VA_ApprovedComplexNumber': '', 'FireplaceFeatures': 'Wood Burning', 'FireplacesTotal': '1', 'Flooring': 'Luxury Vinyl Plank', 'FloorLocationNumber': '', 'FoundationDetails': 'Pillar/Post/Pier', 'FreightDoors': '', 'FrontageFeet': '', 'FrontageLength': '', 'FurnishedYN': '', 'GarageLength': '', 'GarageSpaces': '0', 'GarageWidth': '', 'GarageYN': '1', 'GreenEnergyEfficient': 'Thermostat', 'GreenEnergyGeneration': '', 'GreenIndoorAirQuality': '', 'GreenLandscaping': '', 'GreenSustainability': '', 'GreenWaterConservation': '', 'GrossAnnualExpenses': '', 'GrossAnnualIncome': '', 'GrossIncomeMultiplier': '', 'HighSchool': '', 'HighSchoolName': 'Northmesqu', 'HOAManagementCompany': '', 'HOAManagementCompanyPhone': '', 'HoldDate': '', 'TransactionIncludes': '', 'InsuranceExpense': '', 'InteriorFeatures': 'Cable TV Available,High Speed Internet Available', 'IntermediateSchoolName': '', 'JuniorHighSchoolName': '', 'LakePumpYN': '0', 'LandLeaseYN': '', 'LaundryFeatures': 'Electric Dryer Hookup,Washer Hookup', 'LeasableArea': '', 'LeaseConditions': '', 'LeaseExpirationDate': '', 'LeaseRateMax': '', 'LeaseRateMin': '', 'LeaseTerm': '', 'LeaseType': '', 'LenderName': '', 'ListAgentMLSProvider': 'Collin County Association Of Realtors', 'ListingTerms': 'Cash,Conventional,FHA', 'ListMLSProvider': 'Collin County Association Of Realtors', 'ListSource': '', 'ListSourceOriginal': '', 'ListSourceVendor': '', 'ListTeamKey': '', 'ListTeamKeyNumeric': '', 'ListTeamName': '', 'Loan1Amount': '', 'Loan1InterestRate': '', 'Loan1Years': '', 'LoanBalance': '', 'LoanInterestRate': '', 'LoanPayment': '', 'LoanPaymentType': 'Other', 'LoanType': 'Treat As Clear', 'KeyboxNumber': '0000', 'LockBoxType': 'Combo', 'LotFeatures': 'Interior Lot,Subdivision', 'LotNumber': '', 'LotSize': 'Less Than .5 Acre (not Zero)', 'LotSizeAcres': '0.1810', 'LotSizeArea': '0.1810', 'LotSizeDimensions': '', 'LotSizeSource': 'Public Records', 'LotSizeSquareFeet': '7884.3600', 'LotSizeUnits': 'Acres', 'LotsSoldPackage': '', 'LotsSoldSeparate': '', 'MiddleOrJuniorSchool': '', 'MiddleSchoolName': 'Vanston', 'MLSNumberSaleOrLease': '', 'MoniesRequired': '', 'MonthlyPetFee': '', 'MortgageCompany': '', 'MoveInDate': '', 'MultiParcelIDYN': '1', 'MultiZoningYN': '', 'MunicipalUtilityDistrictYN': '0', 'NetOperationIncome': '', 'NonRefundablePetFeeYN': '', 'NoticeSurveillanceDevicesPresent': 'None', 'NumberOfBarns': '', 'NumberOfBuildings': '', 'NumberOfDaysGuestsAllowed': '', 'NumberOfDiningAreas': '1', 'NumberOfLakes': '', 'NumberOfLeaseableSpaces': '', 'NumberOfLivingAreas': '1', 'NumberOfLots': '', 'NumberOfPetsAllowed': '', 'NumberOfResidences': '', 'NumberOfSeparateWaterMeters': '', 'NumberOfSpacesLeased': '', 'NumberOfStallsInBarn1': '', 'NumberOfStallsInBarn2': '', 'NumberOfStallsInBarn3': '', 'NumberOfTanksAndPonds': '', 'NumberOfUnitsTotal': '', 'NumberOfVehicles': '', 'NumberOfWells': '', 'OccupancyRate': '', 'OccupantName': '', 'OccupantPhoneAlternative': '', 'OccupantType': 'Vacant', 'OpenParkingSpaces': '', 'OpenParkingYN': '', 'OperatingExpenseIncludes': '', 'OriginalMortgageDate': '', 'OriginatingSystemKey': '', 'OriginatingSystemTimestamp': '', 'OtherStructures': '', 'OwnerName': 'Sunique Homes Realty', 'OwnerPays': '', 'OwnerPermissionToVideoYN': '', 'OwnerPhone': '', 'OwnerPhoneAlternative': '', 'ParcelNumber2': '', 'ParkingFeatures': 'Converted Garage,Outside', 'PetsAllowed': '', 'PlannedDevelopment': '', 'PlattedWaterfrontBoundary': '', 'PoolFeatures': '', 'PoolYN': '0', 'Possession': 'Closing/Funding', 'PossibleUse': '', 'PrimarySchoolName': '', 'PrivateOfficeRemarks': '', 'PropertyAttachedYN': '0', 'RanchName': '', 'RangePriceYN': '', 'Restrictions': 'None', 'RETSUpdateTransactionYN': '', 'RoadAssessmentYN': '', 'RoadFrontageDistance': '', 'RoadFrontageType': '', 'RoadSurfaceType': '', 'Roof': 'Composition', 'SchoolDistrict': 'Mesquite ISD', 'SecondMortgageYN': '0', 'SecurityFeatures': '', 'SellerContributions': '6625', 'SeniorCommunityYN': '0', 'SeniorHighSchoolName': '', 'Sewer': '', 'ShowingContactPhone': '800-746-9464', 'ShowingContactPhoneExt': '', 'ShowingContactType': 'ShowingTime - CSS', 'ShowingInstructions': 'Showing Time Go and Show. Please lock all doors and windows after showing', 'ShowingInstructionsSecured': '', 'ShowingRequirements': 'ShowingTime-CSS', 'SmartHomeFeaturesApporPassYN': '0', 'SoilType': 'Unknown', 'SpecialNotes': '', 'SpecialTaxingEntities': '0', 'SQFTGross': '', 'StructuralStyle': 'Single Detached', 'SubAgencyCompensation': '0', 'SubAgencyCompensationType': '%', 'SubdividedYN': '', 'SubdivisionName': 'Casa View Heights 16 Sec 05', 'SurfaceRights': '', 'TaxBlock': '13', 'TaxLegalDescription': 'CASA VIEW HEIGHTS 16 5TH SEC BLK 13 LOT 28', 'Tenancy': '', 'TenantPays': '', 'ThirdPartyAssistanceProgramYN': '0', 'TitleCompanyClosing': '', 'TitleCompanyLocation': '972-377-2158', 'TitleCompanyPhone': 'One Cowboys Way, Ste 260', 'TitleCompanyPreferred': 'Lawyers Title', 'Topography': '', 'TransactionType': 'For Sale', 'UnexemptTaxes': '4077', 'URLNonPublic1': '', 'URLNonPublic2': '', 'URLNonPublic3': '', 'URLNonPublic4': '', 'URLNonPublic5': '', 'USProperty_MUI': '411107579', 'Utilities': 'City Sewer,City Water', 'Vegetation': '', 'VirtualTourURLBranded': '', 'VirtualTourURLUnbranded': 'https://www.propertypanorama.com/instaview/ntreis/20012516', 'WalkScore': '', 'WaterbodyName': '', 'WaterfrontFeatures': '', 'WaterfrontYN': '0', 'WillSubdivide': 'No', 'WillSubdivideYN': '', 'YearBuiltDetails': 'Preowned', 'ZoningDescription': '', 'GeocodeConfidence': 'High', 'PropertyKey': '48113|38033500130280000|1|61341462', 'PropertyMatch': 'APN', 'BuyerOfficeManager': '', 'BuyerOfficeManagerKeyNumeric': '', 'BuyerOfficeManagerLicense': '', 'BuyerOfficeManagerMLSID': '', 'BuyerOfficeManagerPhone': '', 'CoBuyerOfficeManager': '', 'CoBuyerOfficeManagerKeyNumeric': '', 'CoBuyerOfficeManagerLicense': '', 'CoBuyerOfficeManagerMLSID': '', 'CoBuyerOfficeManagerPhone': '', 'CoListOfficeManager': '', 'CoListOfficeManagerKeyNumeric': '', 'CoListOfficeManagerLicense': '', 'CoListOfficeManagerMLSID': '', 'CoListOfficeManagerPhone': '', 'HorsePermittedYN': '0', 'ListOfficeManager': 'Jay Fang', 'ListOfficeManagerKeyNumeric': '61521704', 'ListOfficeManagerLicense': '0671181', 'ListOfficeManagerMLSID': '0671181', 'ListOfficeManagerPhone': '469-500-1268', 'ListPriceLow': '', 'ListPriceLowSystem': '', 'OtherEquipment': '', 'PatioAndPorchFeatures': '', 'WindowFeatures': '', 'LockBoxLocation': '', 'PropertyAssociationFeeType': '', 'BarnsCount': '0', 'GreenVerificationCount': '0', 'LeaseTermDescription': '', 'OccupantPhone': '', 'LeasedPriceUnits': '', 'NumberOfParkingSpaces': '', 'ClosedRemarks': '', 'RATIO_ClosePrice_By_LotSizeAcres': '1464088.39779', 'RATIO_CurrentPrice_By_LotSizeAcres': '1464088.39779', 'RATIO_ListPrice_By_LotSizeAcres': '1435911.60221', 'ConstructionMaterialsWalls': '', 'AuctionHighPrice': '', 'ShowingAttendedYN': '0', 'AccessCode': '', 'BuyerAgentTextingAllowedYN': '', 'CoBuyerAgentTextingAllowedYN': '', 'CoListAgentTextingAllowedYN': '1', 'GarageHeight': '', 'ListAgentTextingAllowedYN': '1', 'PropertyManagedBy': '', 'Levels': 'One', 'TaxLot': '28'}\n",
            "\n",
            "This value exists in Website\n",
            "\n",
            "This value exists in Website\n",
            "\n",
            "This value exists in Website\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(main()) \n",
        "    #5005 Bama Drive, Arlington, Texas 76017\n",
        "    # 20094580"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj1cRQN-lptG"
      },
      "source": [
        "# No Need to Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "H03LHn44G9AS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacdc671-2bc9-4b05-8133-62810d1a8d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arapaho East 04 2nd Inst\n"
          ]
        }
      ],
      "source": [
        "login_url = 'https://ntrdd.mlsmatrix.com/rets/Login.ashx' \n",
        "username = '0671181_NID'\n",
        "password = 'Rt$tg6jx'\n",
        "rets_client = Session(login_url, username, password)\n",
        "rets_client.login()\n",
        "\n",
        "\n",
        "result = rets_client.search(resource='Property', resource_class='Property', dmql_query='(ListingId = {})'.format(20094580))\n",
        "for item in result:\n",
        "  print(item['SubdivisionName'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "8hdvFAW0bEeX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "d2e04c02-13f7-46ac-9a38-f62ba24d0e00"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-ec78e512a2f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"地址\"\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('test.csv')\n",
        "df.rename(columns={ df.columns[0]: \"地址\" }, inplace = True)\n",
        "df.to_csv('test1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fbd5Dk_FVS1"
      },
      "outputs": [],
      "source": [
        "#df.rename(columns={ df.columns[0]: \"地址\" }, inplace = True)\n",
        "#df.to_csv('test1.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pj1cRQN-lptG"
      ],
      "name": "Rest_Data Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}