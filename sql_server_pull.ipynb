{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sql server pull.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/penny1xu/RESTS/blob/main/sql_server_pull.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "W5ToGbiPEptx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f6d960-da05-45af-d584-65f324ec8054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: censusgeocode in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: requests-toolbelt<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from censusgeocode) (0.9.1)\n",
            "Requirement already satisfied: requests[security]<3,>=2.27.0 in /usr/local/lib/python3.7/dist-packages (from censusgeocode) (2.28.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rets in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from rets) (0.16.0)\n",
            "Requirement already satisfied: xmltodict>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from rets) (0.13.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from rets) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from rets) (2.28.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2.10)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unixodbc-dev is already the newest version (2.3.7).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyodbc in /usr/local/lib/python3.7/dist-packages (4.0.32)\n"
          ]
        }
      ],
      "source": [
        "#import package\n",
        "!pip install censusgeocode\n",
        "!pip install rets\n",
        "!sudo apt-get install unixodbc-dev\n",
        "!pip install pyodbc\n",
        "import csv\n",
        "import pandas as pd\n",
        "import censusgeocode as cg\n",
        "import numpy as np\n",
        "import sys\n",
        "from rets import Session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
        "curl https://packages.microsoft.com/config/ubuntu/16.04/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
        "sudo apt-get update\n",
        "sudo ACCEPT_EULA=Y apt-get -q -y install msodbcsql17"
      ],
      "metadata": {
        "id": "bJufduI8Jtby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05571750-1c5a-4f8d-9121-ce05b3b815d5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:3 https://packages.microsoft.com/ubuntu/16.04/prod xenial InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (152 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "msodbcsql17 is already the newest version (17.8.1.1-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "\r100   983  100   983    0     0   6687      0 --:--:-- --:--:-- --:--:--  6687\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100    79  100    79    0     0    612      0 --:--:-- --:--:-- --:--:--   617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyodbc \n",
        "import pandas as pd \n",
        "conn = pyodbc.connect(DRIVER = '{ODBC Driver 17 for SQL Server}',\n",
        "                      SERVER = '76.184.235.171,1433',\n",
        "                      DATABASE = 'RES_DB',\n",
        "                      UID = 'user123',\n",
        "                      PWD = 'Sunique123')\n",
        "\n",
        "data = pd.DataFrame()\n",
        "cursor = conn.cursor()\n",
        "rows = cursor.execute(\"SELECT TOP(10) * FROM [RES_DB].[dbo].[Inventory] WHERE [IsSold] = 1\")\n",
        "rows = cursor.fetchall()\n",
        "#for row in rows:\n",
        "   # print(row)\n",
        "data = pd.DataFrame([tuple(t) for t in rows]) \n",
        "data.columns =['InventoryId', 'Address', 'IsSold']\n",
        "print(data)\n",
        "inVid = []\n",
        "for item in data['InventoryId']:\n",
        "  inVid.append(item)\n",
        "#conn.commit()\n",
        "inVid\n",
        "#data['InventoryId'] = data['InventoryId'].astype(int)  \n"
      ],
      "metadata": {
        "id": "jXNgXVjkJt_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc55db2a-c080-4c49-8c6f-a2014ddc88e2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   InventoryId                                            Address  IsSold\n",
            "0            9        206 E Ridgewood Drive, Garland, Texas 75041    True\n",
            "1           10            310 Colonel Drive, Garland, Texas 75043    True\n",
            "2           11  403 Chancellorsville Drive, Mesquite, TX 75149...    True\n",
            "3           13          723 Caladium Drive, Mesquite, Texas 75149    True\n",
            "4           14          813 Gregory Ave, Bedford, TX 76022(NW WS)    True\n",
            "5           15           836 Russell Ln, Bedford, TX 76022(NW WS)    True\n",
            "6           17      158 Eastwood Place, Lewisville, TX 75067-4315    True\n",
            "7           18        1320 Lanemar Drive, Mesquite, TX 75149-2372    True\n",
            "8           21             1815 Mimosa Avenue, Plano, Texas 75074    True\n",
            "9           24             2104 Holt Road, Arlington, Texas 76006    True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 10, 11, 13, 14, 15, 17, 18, 21, 24]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "cob7JdYQuRAG"
      },
      "outputs": [],
      "source": [
        "\n",
        "def findifNull(lo_left, lo_right, la_left, la_right, research, zip):\n",
        "    result = research.search(resource='Property', resource_class='Property', dmql_query='(MlsStatus = SLD), (CloseDate = 2022-01-01-2022-05-31), (Longitude = {}+), (Longitude = {}-), (Latitude = {}+), (Latitude = {}-), (PostalCode = {})'.format(lo_left, lo_right, la_left, la_right, zip))\n",
        "    count = 0\n",
        "    lis = []\n",
        "    di = {}\n",
        "    df = pd.DataFrame()\n",
        "    for item in result:\n",
        "        if(item['PropertyType'] == 'Residential' and item['PropertySubType'] == 'Single Family Residence'):\n",
        "            df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True)\n",
        "            count += 1\n",
        "            di = item\n",
        "    for key in di:\n",
        "        lis.append(key)\n",
        "    if(count >= 5):\n",
        "        df = df.T\n",
        "        df.columns = lis\n",
        "        return df\n",
        "    else:\n",
        "        lo_left -= 0.008\n",
        "        lo_right += 0.008\n",
        "        la_left -= 0.008\n",
        "        la_right += 0.008\n",
        "        return findifNull(lo_left, lo_right, la_left, la_right, research, zip)\n",
        "\n",
        "def nullZiphouse(house_leftLa,house_rightLa,house_leftLo,house_rightLo,research,column):\n",
        "  result = research.search(resource = 'Property', resource_class='Property', dmql_query='(MlsStatus = SLD), (CloseDate = 2022-01-01-2022-06-30), (Longitude = {}+), (Longitude = {}-), (Latitude = {}+), (Latitude = {}-)'.format(house_leftLo, house_rightLo, house_leftLa, house_rightLa))\n",
        "  count = 0\n",
        "  df = pd.DataFrame()\n",
        "  for item in result: \n",
        "    if(item['PropertyType'] == 'Residential' and item['PropertySubType'] == 'Single Family Residence'):\n",
        "            df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True) #?\n",
        "            count += 1         \n",
        "  if(count >= 5):  \n",
        "    df = df.T\n",
        "    df.columns = column # \n",
        "    return df\n",
        "  else:\n",
        "    house_leftLo -= 0.008\n",
        "    house_rightLo += 0.008\n",
        "    house_leftLa -= 0.008\n",
        "    house_rightLa += 0.008\n",
        "    return nullZiphouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, research, column)\n",
        "    \n",
        "def findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, house_leftSqt, house_rightSqt, research, column, zip, a, b, time1, time2):\n",
        "    basic = house_leftSqt\n",
        "    count = 0\n",
        "    df = pd.DataFrame()\n",
        "    result = research.search(resource='Property', resource_class='Property', dmql_query='(MlsStatus = SLD), (CloseDate = 2022-01-01-2022-05-31), (YearBuilt = {}+), (YearBuilt = {}-), (Longitude = {}+), (Longitude = {}-), (Latitude = {}+), (Latitude = {}-), (LivingArea = {}+), (LivingArea = {}-), (PostalCode = {})'.format(time1, time2, house_leftLo, house_rightLo, house_leftLa, house_rightLa, house_leftSqt, house_rightSqt, zip))\n",
        "    for item in result:\n",
        "        if(item['PropertyType'] == 'Residential' and item['PropertySubType'] == 'Single Family Residence'):\n",
        "            df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True)\n",
        "            count += 1\n",
        "    if(count >= 5):\n",
        "        df = df.T\n",
        "        df.columns = column\n",
        "        return df\n",
        "    else:\n",
        "        house_leftLa -= 0.008\n",
        "        house_rightLa += 0.008\n",
        "        house_leftLo -= 0.008\n",
        "        house_rightLo += 0.008\n",
        "        b +=1\n",
        "        if(b >= 12):\n",
        "          house_leftLo += 0.096\n",
        "          house_rightLo -= 0.096\n",
        "          house_leftLa += 0.096\n",
        "          house_rightLa -= 0.096  \n",
        "          return nullZiphouse(house_leftLa,house_rightLa,house_leftLo,house_rightLo,research,column)\n",
        "\n",
        "  #Living Area\n",
        "        if(a == 0):\n",
        "            if(basic <= 1100):\n",
        "                house_leftSqt -= 100\n",
        "                house_rightSqt += 100\n",
        "            elif(basic <= 2200):\n",
        "                house_leftSqt -= 200\n",
        "                house_rightSqt += 200\n",
        "            else:\n",
        "                house_leftSqt -= 300\n",
        "                house_rightSqt += 300\n",
        "\n",
        "            a += 1\n",
        "        return findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, house_leftSqt, house_rightSqt, research, column, zip, a, b, time1, time2)\n",
        "\n",
        "    \n",
        "def findfirst(result):\n",
        "    count = 0\n",
        "    for item in result:\n",
        "        count += 1\n",
        "    if(count == 0):\n",
        "        return False\n",
        "    else:\n",
        "        return True    \n",
        "    \n",
        "def get(number, finalN, code, i, rets_client, street, city, state):\n",
        "    pulled_value = {}\n",
        "    result = rets_client.search(resource='Property', resource_class='Property', dmql_query='(StreetNumber = {}),(StreetName = {}),(PostalCode = {})'.format(number[i],finalN[i],code[i]))\n",
        "    for item in result:\n",
        "        pulled_value = item\n",
        "    if(len(pulled_value) != 0):\n",
        "        column = []\n",
        "        for key in pulled_value:\n",
        "            column.append(key)\n",
        "        print(\"\\nThis value exists in Website\")\n",
        "  # get whole row value\n",
        "  #get each value\n",
        "        zip = pulled_value.get('PostalCode')\n",
        "        house_leftLa = float(pulled_value.get('Latitude'))\n",
        "        house_rightLa = float(pulled_value.get('Latitude')) \n",
        "        house_leftLo = float(pulled_value.get('Longitude'))\n",
        "        house_rightLo = float(pulled_value.get('Longitude'))\n",
        "        house_leftSqt = float(pulled_value.get('LivingArea'))\n",
        "        house_rightSqt = float(pulled_value.get('LivingArea'))\n",
        "        time1 = int(pulled_value.get('YearBuilt'))\n",
        "        time2 = int(pulled_value.get('YearBuilt'))\n",
        "        if time1 < 1990:\n",
        "            time1 = 0 \n",
        "            time2 = 1989\n",
        "        elif time1 >=1990 and time1 <2011:\n",
        "            time1 = 1990\n",
        "            time2 = 2010\n",
        "        elif time1 >= 2011 and time1 < 2022:\n",
        "            time1 = 2011\n",
        "            time2 = 2021\n",
        "        else:\n",
        "            time1 = 2022\n",
        "            time2 = 9999\n",
        "        a = 0\n",
        "        b = 0\n",
        "        result1 = findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, house_leftSqt, house_rightSqt, rets_client, column, zip, a, b, time1, time2)\n",
        "        result1 = result1[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp','StateOrProvince',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt']]\n",
        "        price = []\n",
        "        for item in result1['ClosePrice']:\n",
        "            item = float(item)\n",
        "            price.append(item)\n",
        "        result1['ClosePrice'] = price\n",
        "        result1['FullAdress'] = result1['StreetNumber'] + \" \" + result1['StreetName'] + result1['City'] + \", \" +result1['StateOrProvince'] + \" \" + result1['PostalCode']\n",
        "\n",
        "        mean1 = result1['ClosePrice'].mean()\n",
        "        top1 = list(result1['ClosePrice'])\n",
        "        top1.sort(reverse = True)\n",
        "        return result1.to_csv('{} {} {}.csv'.format(number[i],finalN[i],code[i])), mean1, top1[0:3]\n",
        "    else:\n",
        "        print('check coordinates')\n",
        "        result = cg.address(street[i], city = city[i], state= state[i], zipcode = code[i])\n",
        "        if(len(result) != 0):\n",
        "            lo_left = result[0]['coordinates']['x']\n",
        "            lo_right = result[0]['coordinates']['x']\n",
        "            la_left = result[0]['coordinates']['y']\n",
        "            la_right = result[0]['coordinates']['y']\n",
        "            result = findifNull(lo_left, lo_right, la_left, la_right, rets_client, code[i])\n",
        "            result = result[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp', 'StateOrProvince',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt']]\n",
        "            price = []\n",
        "            for item in result['ClosePrice']:\n",
        "                item = float(item)\n",
        "                price.append(item)\n",
        "            result['ClosePrice'] = price\n",
        "            result['FullAddress'] = result['StreetNumber'] + \" \" + result['StreetName'] + result['City'] + \", \" +result['StateOrProvince'] + \" \" + result['PostalCode']\n",
        "            mean = result['ClosePrice'].mean()\n",
        "            top = list(result['ClosePrice'])\n",
        "            top.sort(reverse = True)\n",
        "            return result, mean, top[0:3]\n",
        "        else:\n",
        "            print('invalid address')\n",
        "            mean = 0\n",
        "            top = 0\n",
        "            return 0, mean, top\n",
        "def judge(i):\n",
        "    if i % 10 == 1:\n",
        "        return 'st'\n",
        "    elif i % 10 == 2:\n",
        "        return 'nd'\n",
        "    elif i % 10 == 3:\n",
        "        return 'rd'\n",
        "    else:\n",
        "        return 'th'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3adca72f-f4fb-4659-f8bb-9d509287ce41",
        "id": "XKtwr_AYIXgu"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check coordinates\n",
            "The mean for 206, E, 75041 is 223667.85714285713\n",
            "The top 3 for 206, E, 75041 are [285000.0, 275000.0, 275000.0]\n",
            "check coordinates\n",
            "The mean for 310, E Ridgewood, 75043 is 282642.7272727273\n",
            "The top 3 for 310, E Ridgewood, 75043 are [370000.0, 370000.0, 332500.0]\n",
            "check coordinates\n",
            "The mean for 403, Colonel, 75149 is 282198.5833333333\n",
            "The top 3 for 403, Colonel, 75149 are [425000.0, 400000.0, 360000.0]\n",
            "check coordinates\n",
            "The mean for 723, Chancellorsville, 75149 is 252392.52631578947\n",
            "The top 3 for 723, Chancellorsville, 75149 are [400000.0, 385000.0, 360000.0]\n",
            "check coordinates\n",
            "The mean for 813, Caladium, 76022 is 311412.5\n",
            "The top 3 for 813, Caladium, 76022 are [402000.0, 373000.0, 360000.0]\n",
            "check coordinates\n",
            "The mean for 836, Gregory, 76022 is 293784.2105263158\n",
            "The top 3 for 836, Gregory, 76022 are [405000.0, 371000.0, 353000.0]\n",
            "check coordinates\n",
            "The mean for 158, Russell, 75067 is 327727.2727272727\n",
            "The top 3 for 158, Russell, 75067 are [515000.0, 475000.0, 440000.0]\n",
            "check coordinates\n",
            "The mean for 1320, Eastwood, 75149 is 224338.66666666666\n",
            "The top 3 for 1320, Eastwood, 75149 are [337000.0, 310500.0, 305000.0]\n",
            "check coordinates\n",
            "The mean for 1815, Lanemar, 75074 is 328675.0\n",
            "The top 3 for 1815, Lanemar, 75074 are [420000.0, 420000.0, 368100.0]\n",
            "check coordinates\n",
            "The mean for 2104, Mimosa, 76006 is 442762.5\n",
            "The top 3 for 2104, Mimosa, 76006 are [1150000.0, 672000.0, 520000.0]\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    login_url = 'https://ntrdd.mlsmatrix.com/rets/Login.ashx' \n",
        "    username = '0671181_NID'\n",
        "    password = 'Rt$tg6jx'\n",
        "    rets_client = Session(login_url, username, password)\n",
        "    rets_client.login()\n",
        "    code = []\n",
        "    name = []\n",
        "    number = []\n",
        "    street = []\n",
        "    city = []\n",
        "    state = []\n",
        "    for item in data['Address']:\n",
        "      a = item.split(',')[0]\n",
        "      b = item.split(',')[2]\n",
        "      c = item.split(',')[1]\n",
        "      street.append(a)\n",
        "      city.append(c)\n",
        "      numbers = a.split()[0]\n",
        "      names = a.split()[1:(len(a.split()) - 1)]\n",
        "      codes = b.split()[1][0:5]\n",
        "      states = b.split()[0]\n",
        "      state.append(states)\n",
        "      code.append(codes)\n",
        "      name.append(names)\n",
        "      number.append(numbers)\n",
        "    finalN = []\n",
        "    for item in name:\n",
        "      string = \"\"\n",
        "      for items in item:\n",
        "        string += items\n",
        "        string += ' '\n",
        "        finalN.append(string[0:len(string) - 1])            \n",
        "    for i in range(len(code)):\n",
        "      result, mean, top = get(number, finalN, code, i, rets_client, street, city, state)\n",
        "      for j in range(len(result['FullAddress'])):\n",
        "        cursor.execute(\"INSERT INTO FinalResult4 (id, Address, ClosePrice) VALUES (?,?,?)\",\n",
        "                inVid[i], \n",
        "                result['FullAddress'][j],\n",
        "                int(result['ClosePrice'][j])\n",
        "                )\n",
        "        \n",
        "      print('The mean for {}, {}, {} is {}'.format(number[i],finalN[i],code[i], mean))\n",
        "      print('The top 3 for {}, {}, {} are {}'.format(number[i],finalN[i],code[i], top))\n",
        "    cursor.commit()\n",
        "    conn.close()\n",
        "    return\n",
        "       \n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    print(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# how to insert value in\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bgngRl7KGDV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a new table\n",
        "# Import CSV\n",
        "\n",
        "\n",
        "# Connect to SQL Server\n",
        "conn = pyodbc.connect(DRIVER = '{ODBC Driver 17 for SQL Server}',\n",
        "                      SERVER = '76.184.235.171,1433',\n",
        "                      DATABASE = 'RES_DB',\n",
        "                      UID = 'user123',\n",
        "                      PWD = 'Sunique123')\n",
        "\n",
        "cursor = conn.cursor()\n",
        "#cursor.execute('drop table if exists FinalResult')\n",
        "# Create Table\n",
        "cursor.execute('''\n",
        "\t\tCREATE TABLE FinalResult4 (\n",
        "\t\t\tid int,\n",
        "\t\t\tAddress nvarchar(max),\n",
        "\t\t\tClosePrice int\n",
        "      FOREIGN KEY (id) REFERENCES Inventory(InventoryId)\n",
        "\t\t\t)\n",
        "               ''')\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "# Insert DataFrame to Table\n",
        "\n"
      ],
      "metadata": {
        "id": "jiwUj2RKFFt4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "385ff8a3-e0d0-4009-ee2e-fd2af51d0e33"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:An unexpected error occurred while tokenizing input\n",
            "The following traceback may be corrupted or invalid\n",
            "The error message is: ('EOF in multi-line string', (1, 15))\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ProgrammingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-5d33734ce119>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mFOREIGN\u001b[0m \u001b[0mKEY\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mREFERENCES\u001b[0m \u001b[0mInventory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInventoryId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \t\t\t)\n\u001b[0;32m---> 22\u001b[0;31m                ''')\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mProgrammingError\u001b[0m: ('42S01', \"[42S01] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]There is already an object named 'FinalResult4' in the database. (2714) (SQLExecDirectW)\")"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "insert data"
      ],
      "metadata": {
        "id": "492Rv8Y9YdV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.frame import DataFrame\n",
        "# insert into sql\n",
        "#data = data.values.tolist()\n",
        "\n",
        "conn = pyodbc.connect(DRIVER = '{ODBC Driver 17 for SQL Server}',\n",
        "                      SERVER = '76.184.235.171,1433',\n",
        "                      DATABASE = 'RES_DB',\n",
        "                      UID = 'user123',\n",
        "                      PWD = 'Sunique123')\n",
        "cursor = conn.cursor()\n",
        "sql = \"INSERT INTO [RES_DB].[dbo].[SearchResult2] (SearchID,Address,IsSold) values(?,?,?)\"\n",
        "cursor.executemany(sql,rows)\n",
        "conn.commit()\n",
        "#cursor.close()\n",
        "#for index, row in df.iterrows():\n",
        "#cursor.execute(\"INSERT INTO [RES_DB].[dbo].[SearchResult2] (SearchID,Address) values(?,?)\", row.InventoryId, row.Address)\n"
      ],
      "metadata": {
        "id": "qpQfN9lWQQec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check data in sql"
      ],
      "metadata": {
        "id": "IpjKXa1UYfYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn = pyodbc.connect(DRIVER = '{ODBC Driver 17 for SQL Server}',\n",
        "                      SERVER = '76.184.235.171,1433',\n",
        "                      DATABASE = 'RES_DB',\n",
        "                      UID = 'user123',\n",
        "                      PWD = 'Sunique123')\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT * FROM [RES_DB].[dbo].[SearchResult2]\")\n",
        "rows = cursor.fetchall()\n",
        "for row in rows:\n",
        "    print(row)\n",
        "cursor.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "ivvqptPE5lD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = pyodbc.connect(DRIVER = '{ODBC Driver 17 for SQL Server}',\n",
        "                      SERVER = '76.184.235.171,1433',\n",
        "                      DATABASE = 'RES_DB',\n",
        "                      UID = 'user123',\n",
        "                      PWD = 'Sunique123')\n",
        "\n",
        "data = pd.DataFrame()\n",
        "cursor = conn.cursor()\n",
        "rows = cursor.execute(\"SELECT * FROM [RES_DB].[dbo].[FinalResult4]\")\n",
        "rows = cursor.fetchall()\n",
        "for row in rows:\n",
        "    print(row)\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "1jX6ZrBlfaBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}