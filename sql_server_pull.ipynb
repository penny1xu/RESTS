{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sql server pull.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/penny1xu/RESTS/blob/main/sql_server_pull.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W5ToGbiPEptx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b33839f-561c-48c3-8382-e27c97d39446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting censusgeocode\n",
            "  Downloading censusgeocode-0.5.2-py3-none-any.whl (9.2 kB)\n",
            "Collecting requests-toolbelt<1,>=0.9.0\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 744 kB/s \n",
            "\u001b[?25hCollecting requests[security]<3,>=2.27.0\n",
            "  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 549 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from requests-toolbelt<1,>=0.9.0->censusgeocode) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt<1,>=0.9.0->censusgeocode) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt<1,>=0.9.0->censusgeocode) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt<1,>=0.9.0->censusgeocode) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt<1,>=0.9.0->censusgeocode) (3.0.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (2.0.12)\n",
            "Installing collected packages: requests, requests-toolbelt, censusgeocode\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed censusgeocode-0.5.2 requests-2.28.0 requests-toolbelt-0.9.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rets\n",
            "  Downloading rets-1.0.0-py2.py3-none-any.whl (22 kB)\n",
            "Collecting xmltodict>=0.11.0\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from rets) (1.15.0)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from rets) (0.16.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from rets) (2.28.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (1.24.3)\n",
            "Installing collected packages: xmltodict, rets\n",
            "Successfully installed rets-1.0.0 xmltodict-0.13.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unixodbc-dev is already the newest version (2.3.4-1.1ubuntu3).\n",
            "unixodbc-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyodbc\n",
            "  Downloading pyodbc-4.0.32.tar.gz (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 5.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyodbc\n",
            "  Building wheel for pyodbc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyodbc: filename=pyodbc-4.0.32-cp37-cp37m-linux_x86_64.whl size=287353 sha256=fd7420a2a4b151450220bd8d2819b6501b1346980da47346def358fec50ba199\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/9c/da/8652fd42e0f662015554f00a9e96fe4f438dfd1ef59787879e\n",
            "Successfully built pyodbc\n",
            "Installing collected packages: pyodbc\n",
            "Successfully installed pyodbc-4.0.32\n"
          ]
        }
      ],
      "source": [
        "#import package\n",
        "!pip install censusgeocode\n",
        "!pip install rets\n",
        "!sudo apt-get install unixodbc-dev\n",
        "!pip install pyodbc\n",
        "import csv\n",
        "import pandas as pd\n",
        "import censusgeocode as cg\n",
        "import numpy as np\n",
        "import sys\n",
        "from rets import Session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
        "curl https://packages.microsoft.com/config/ubuntu/16.04/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
        "sudo apt-get update\n",
        "sudo ACCEPT_EULA=Y apt-get -q -y install msodbcsql17"
      ],
      "metadata": {
        "id": "bJufduI8Jtby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d824a0-ff71-437b-aaa9-e16a3d91c054"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:4 https://packages.microsoft.com/ubuntu/16.04/prod xenial InRelease [4,011 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 https://packages.microsoft.com/ubuntu/16.04/prod xenial/main amd64 Packages [305 kB]\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,006 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,861 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,521 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,294 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,297 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,040 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n",
            "Fetched 12.6 MB in 4s (3,479 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libodbc1 odbcinst odbcinst1debian2 unixodbc unixodbc-dev\n",
            "Suggested packages:\n",
            "  unixodbc-bin\n",
            "The following NEW packages will be installed:\n",
            "  msodbcsql17 unixodbc\n",
            "The following packages will be upgraded:\n",
            "  libodbc1 odbcinst odbcinst1debian2 unixodbc-dev\n",
            "4 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 1,458 kB of archives.\n",
            "After this operation, 152 kB of additional disk space will be used.\n",
            "Get:1 https://packages.microsoft.com/ubuntu/16.04/prod xenial/main amd64 odbcinst amd64 2.3.7 [12.0 kB]\n",
            "Get:2 https://packages.microsoft.com/ubuntu/16.04/prod xenial/main amd64 unixodbc-dev amd64 2.3.7 [37.1 kB]\n",
            "Get:3 https://packages.microsoft.com/ubuntu/16.04/prod xenial/main amd64 odbcinst1debian2 amd64 2.3.7 [135 kB]\n",
            "Get:4 https://packages.microsoft.com/ubuntu/16.04/prod xenial/main amd64 libodbc1 amd64 2.3.7 [511 kB]\n",
            "Get:5 https://packages.microsoft.com/ubuntu/16.04/prod xenial/main amd64 unixodbc amd64 2.3.7 [19.6 kB]\n",
            "Get:6 https://packages.microsoft.com/ubuntu/16.04/prod xenial/main amd64 msodbcsql17 amd64 17.8.1.1-1 [744 kB]\n",
            "Fetched 1,458 kB in 0s (4,028 kB/s)\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 155639 files and directories currently installed.)\r\n",
            "Preparing to unpack .../0-odbcinst_2.3.7_amd64.deb ...\r\n",
            "Unpacking odbcinst (2.3.7) over (2.3.4-1.1ubuntu3) ...\r\n",
            "Preparing to unpack .../1-unixodbc-dev_2.3.7_amd64.deb ...\r\n",
            "Unpacking unixodbc-dev (2.3.7) over (2.3.4-1.1ubuntu3) ...\r\n",
            "Preparing to unpack .../2-odbcinst1debian2_2.3.7_amd64.deb ...\r\n",
            "Unpacking odbcinst1debian2:amd64 (2.3.7) over (2.3.4-1.1ubuntu3) ...\r\n",
            "Preparing to unpack .../3-libodbc1_2.3.7_amd64.deb ...\r\n",
            "Unpacking libodbc1:amd64 (2.3.7) over (2.3.4-1.1ubuntu3) ...\r\n",
            "Selecting previously unselected package unixodbc.\r\n",
            "Preparing to unpack .../4-unixodbc_2.3.7_amd64.deb ...\r\n",
            "Unpacking unixodbc (2.3.7) ...\r\n",
            "Selecting previously unselected package msodbcsql17.\r\n",
            "Preparing to unpack .../5-msodbcsql17_17.8.1.1-1_amd64.deb ...\r\n",
            "debconf: unable to initialize frontend: Dialog\r\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\r\n",
            "debconf: falling back to frontend: Readline\r\n",
            "Unpacking msodbcsql17 (17.8.1.1-1) ...\r\n",
            "Setting up libodbc1:amd64 (2.3.7) ...\r\n",
            "Setting up odbcinst1debian2:amd64 (2.3.7) ...\r\n",
            "Setting up odbcinst (2.3.7) ...\r\n",
            "Setting up unixodbc (2.3.7) ...\r\n",
            "Setting up unixodbc-dev (2.3.7) ...\r\n",
            "Setting up msodbcsql17 (17.8.1.1-1) ...\r\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\r\n",
            "\r\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "\r100   983  100   983    0     0   5993      0 --:--:-- --:--:-- --:--:--  5957\r100   983  100   983    0     0   5993      0 --:--:-- --:--:-- --:--:--  5957\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100    79  100    79    0     0    831      0 --:--:-- --:--:-- --:--:--   831\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyodbc \n",
        "import pandas as pd \n",
        "conn = pyodbc.connect(DRIVER = '{ODBC Driver 17 for SQL Server}',\n",
        "                      SERVER = '76.184.235.171,1433',\n",
        "                      DATABASE = 'RES_DB',\n",
        "                      UID = 'user123',\n",
        "                      PWD = 'Sunique123')\n",
        "\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT * FROM [RES_DB].[dbo].[Inventory] WHERE [IsSold] = 1\")\n",
        "rows = cursor.fetchall()\n",
        "df = pd.DataFrame()\n",
        "address = []\n",
        "for row in rows:\n",
        "  address.append(row[1])   \n",
        "cursor.close()\n",
        "df['地址'] = address\n",
        "df.to_csv('df1.csv')"
      ],
      "metadata": {
        "id": "jXNgXVjkJt_u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cob7JdYQuRAG",
        "outputId": "392d71fd-14bd-41e5-d8d8-857ae36157a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "invalid address!\n",
            "check coordinates\n",
            "invalid address\n",
            "The mean for 4368, N, 75043 is 0\n",
            "The top 3 for 4368, N, 75043 are 0\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def findifNull(lo_left, lo_right, la_left, la_right, research, zip):\n",
        "    result = research.search(resource='Property', resource_class='Property', dmql_query='(MlsStatus = SLD), (CloseDate = 2022-01-01-2022-05-31), (Longitude = {}+), (Longitude = {}-), (Latitude = {}+), (Latitude = {}-), (PostalCode = {})'.format(lo_left, lo_right, la_left, la_right, zip))\n",
        "    count = 0\n",
        "    lis = []\n",
        "    di = {}\n",
        "    df = pd.DataFrame()\n",
        "    for item in result:\n",
        "        if(item['PropertyType'] == 'Residential' and item['PropertySubType'] == 'Single Family Residence'):\n",
        "            df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True)\n",
        "            count += 1\n",
        "            di = item\n",
        "    for key in di:\n",
        "        lis.append(key)\n",
        "    if(count >= 5):\n",
        "        df = df.T\n",
        "        df.columns = lis\n",
        "        return df\n",
        "    else:\n",
        "        lo_left -= 0.008\n",
        "        lo_right += 0.008\n",
        "        la_left -= 0.008\n",
        "        la_right += 0.008\n",
        "        return findifNull(lo_left, lo_right, la_left, la_right, research, zip)\n",
        "\n",
        "def nullZiphouse(house_leftLa,house_rightLa,house_leftLo,house_rightLo,research,column):\n",
        "  result = research.search(resource = 'Property', resource_class='Property', dmql_query='(MlsStatus = SLD), (CloseDate = 2022-01-01-2022-06-30), (Longitude = {}+), (Longitude = {}-), (Latitude = {}+), (Latitude = {}-)'.format(house_leftLo, house_rightLo, house_leftLa, house_rightLa))\n",
        "  count = 0\n",
        "  df = pd.DataFrame()\n",
        "  for item in result: \n",
        "    if(item['PropertyType'] == 'Residential' and item['PropertySubType'] == 'Single Family Residence'):\n",
        "            df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True) #?\n",
        "            count += 1         \n",
        "  if(count >= 5):  \n",
        "    df = df.T\n",
        "    df.columns = column # \n",
        "    return df\n",
        "  else:\n",
        "    house_leftLo -= 0.008\n",
        "    house_rightLo += 0.008\n",
        "    house_leftLa -= 0.008\n",
        "    house_rightLa += 0.008\n",
        "    return nullZiphouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, research, column)\n",
        "    \n",
        "def findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, house_leftSqt, house_rightSqt, research, column, zip, a, b, time1, time2):\n",
        "    basic = house_leftSqt\n",
        "    count = 0\n",
        "    df = pd.DataFrame()\n",
        "    result = research.search(resource='Property', resource_class='Property', dmql_query='(MlsStatus = SLD), (CloseDate = 2022-01-01-2022-05-31), (YearBuilt = {}+), (YearBuilt = {}-), (Longitude = {}+), (Longitude = {}-), (Latitude = {}+), (Latitude = {}-), (LivingArea = {}+), (LivingArea = {}-), (PostalCode = {})'.format(time1, time2, house_leftLo, house_rightLo, house_leftLa, house_rightLa, house_leftSqt, house_rightSqt, zip))\n",
        "    for item in result:\n",
        "        if(item['PropertyType'] == 'Residential' and item['PropertySubType'] == 'Single Family Residence'):\n",
        "            df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True)\n",
        "            count += 1\n",
        "    if(count >= 5):\n",
        "        df = df.T\n",
        "        df.columns = column\n",
        "        return df\n",
        "    else:\n",
        "        house_leftLa -= 0.008\n",
        "        house_rightLa += 0.008\n",
        "        house_leftLo -= 0.008\n",
        "        house_rightLo += 0.008\n",
        "        b +=1\n",
        "        if(b >= 12):\n",
        "          house_leftLo += 0.096\n",
        "          house_rightLo -= 0.096\n",
        "          house_leftLa += 0.096\n",
        "          house_rightLa -= 0.096  \n",
        "          return nullZiphouse(house_leftLa,house_rightLa,house_leftLo,house_rightLo,research,column)\n",
        "\n",
        "  #Living Area\n",
        "        if(a == 0):\n",
        "            if(basic <= 1100):\n",
        "                house_leftSqt -= 100\n",
        "                house_rightSqt += 100\n",
        "            elif(basic <= 2200):\n",
        "                house_leftSqt -= 200\n",
        "                house_rightSqt += 200\n",
        "            else:\n",
        "                house_leftSqt -= 300\n",
        "                house_rightSqt += 300\n",
        "\n",
        "            a += 1\n",
        "        return findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, house_leftSqt, house_rightSqt, research, column, zip, a, b, time1, time2)\n",
        "\n",
        "    \n",
        "def findfirst(result):\n",
        "    count = 0\n",
        "    for item in result:\n",
        "        count += 1\n",
        "    if(count == 0):\n",
        "        return False\n",
        "    else:\n",
        "        return True    \n",
        "    \n",
        "def insertId(pulled_value, mls, rets_client):\n",
        "    \n",
        "    column = []\n",
        "    for key in pulled_value:\n",
        "        column.append(key)\n",
        "    print(\"\\nThis value exists in Website\")\n",
        "  # get whole row value\n",
        "  #get each value\n",
        "    zip = pulled_value.get('PostalCode')\n",
        "    house_leftLa = float(pulled_value.get('Latitude'))\n",
        "    house_rightLa = float(pulled_value.get('Latitude')) \n",
        "    house_leftLo = float(pulled_value.get('Longitude'))\n",
        "    house_rightLo = float(pulled_value.get('Longitude'))\n",
        "    house_leftSqt = float(pulled_value.get('LivingArea'))\n",
        "    house_rightSqt = float(pulled_value.get('LivingArea'))\n",
        "    time1 = int(pulled_value.get('YearBuilt'))\n",
        "    time2 = int(pulled_value.get('YearBuilt'))\n",
        "    if time1 < 1990:\n",
        "        time1 = 0 \n",
        "        time2 = 1989\n",
        "    elif time1 >=1990 and time1 <2011:\n",
        "        time1 = 1990\n",
        "        time2 = 2010\n",
        "    elif time1 >= 2011 and time1 < 2022:\n",
        "        time1 = 2011\n",
        "        time2 = 2021\n",
        "    else:\n",
        "        time1 = 2022\n",
        "        time2 = 9999\n",
        "    a = 0\n",
        "    b = 0\n",
        "    result1 = findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, house_leftSqt, house_rightSqt, rets_client, column, zip, a, b, time1, time2)        \n",
        "    result1 = result1[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt']]\n",
        "    price = []\n",
        "    for item in result1['ClosePrice']:\n",
        "        item = float(item)\n",
        "        price.append(item)\n",
        "    result1['ClosePrice'] = price\n",
        "    mean1 = result1['ClosePrice'].mean()\n",
        "    top1 = list(result1['ClosePrice'])\n",
        "    top1.sort(reverse = True)\n",
        "    print('The mean for {} is {}'.format(mls, mean1))\n",
        "    print('The top 3 for {} are {}'.format(mls, top1[0:3]))\n",
        "    return result1.to_csv('{}.csv'.format(mls))\n",
        "\n",
        "def findAdd(address, city, state, zip, rets_client):\n",
        "    result = cg.address(address, city = city, state= state,zipcode = zip)\n",
        "    lo_left = result[0]['coordinates']['x']\n",
        "    lo_right = result[0]['coordinates']['x']\n",
        "    la_left = result[0]['coordinates']['y']\n",
        "    la_right = result[0]['coordinates']['y']\n",
        "    result = findifNull(lo_left, lo_right, la_left, la_right, rets_client, zip)\n",
        "    result = result[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt']]\n",
        "    price = []\n",
        "    for item in result['ClosePrice']:\n",
        "        item = float(item)\n",
        "        price.append(item)\n",
        "    result['ClosePrice'] = price\n",
        "    mean = result['ClosePrice'].mean()\n",
        "    top = list(result['ClosePrice'])\n",
        "    top.sort(reverse = True)\n",
        "    print('The mean for {}, {}, {} is {}'.format(address, state, zip, mean))\n",
        "    print('The top 3 for {}, {}, {} are {}'.format(address, state, zip, top))\n",
        "    return result.to_csv('{},{},{}.csv'.format(address, state, zip))\n",
        "    \n",
        "def get(number, finalN, code, i, rets_client, street, city, state):\n",
        "    pulled_value = {}\n",
        "    result = rets_client.search(resource='Property', resource_class='Property', dmql_query='(StreetNumber = {}),(StreetName = {}),(PostalCode = {})'.format(number[i],finalN[i],code[i]))\n",
        "    for item in result:\n",
        "        pulled_value = item\n",
        "    if(len(pulled_value) != 0):\n",
        "        column = []\n",
        "        for key in pulled_value:\n",
        "            column.append(key)\n",
        "        print(\"\\nThis value exists in Website\")\n",
        "  # get whole row value\n",
        "  #get each value\n",
        "        zip = pulled_value.get('PostalCode')\n",
        "        house_leftLa = float(pulled_value.get('Latitude'))\n",
        "        house_rightLa = float(pulled_value.get('Latitude')) \n",
        "        house_leftLo = float(pulled_value.get('Longitude'))\n",
        "        house_rightLo = float(pulled_value.get('Longitude'))\n",
        "        house_leftSqt = float(pulled_value.get('LivingArea'))\n",
        "        house_rightSqt = float(pulled_value.get('LivingArea'))\n",
        "        time1 = int(pulled_value.get('YearBuilt'))\n",
        "        time2 = int(pulled_value.get('YearBuilt'))\n",
        "        if time1 < 1990:\n",
        "            time1 = 0 \n",
        "            time2 = 1989\n",
        "        elif time1 >=1990 and time1 <2011:\n",
        "            time1 = 1990\n",
        "            time2 = 2010\n",
        "        elif time1 >= 2011 and time1 < 2022:\n",
        "            time1 = 2011\n",
        "            time2 = 2021\n",
        "        else:\n",
        "            time1 = 2022\n",
        "            time2 = 9999\n",
        "        a = 0\n",
        "        b = 0\n",
        "        result1 = findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, house_leftSqt, house_rightSqt, rets_client, column, zip, a, b, time1, time2)\n",
        "        result1 = result1[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt']]\n",
        "        price = []\n",
        "        for item in result1['ClosePrice']:\n",
        "            item = float(item)\n",
        "            price.append(item)\n",
        "        result1['ClosePrice'] = price\n",
        "        mean1 = result1['ClosePrice'].mean()\n",
        "        top1 = list(result1['ClosePrice'])\n",
        "        top1.sort(reverse = True)\n",
        "        return result1.to_csv('{} {} {}.csv'.format(number[i],finalN[i],code[i])), mean1, top1[0:3]\n",
        "    else:\n",
        "        print('check coordinates')\n",
        "        result = cg.address(street[i], city = city[i], state= state[i], zipcode = code[i])\n",
        "        if(len(result) != 0):\n",
        "            lo_left = result[0]['coordinates']['x']\n",
        "            lo_right = result[0]['coordinates']['x']\n",
        "            la_left = result[0]['coordinates']['y']\n",
        "            la_right = result[0]['coordinates']['y']\n",
        "            result = findifNull(lo_left, lo_right, la_left, la_right, rets_client, code[i])\n",
        "            result = result[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt']]\n",
        "            price = []\n",
        "            for item in result['ClosePrice']:\n",
        "                item = float(item)\n",
        "                price.append(item)\n",
        "            result['ClosePrice'] = price\n",
        "            mean = result['ClosePrice'].mean()\n",
        "            top = list(result['ClosePrice'])\n",
        "            top.sort(reverse = True)\n",
        "            return result.to_csv('{} {} {}.csv'.format(number[i],finalN[i],code[i])), mean, top[0:3]\n",
        "        else:\n",
        "            print('invalid address')\n",
        "            mean = 0\n",
        "            top = 0\n",
        "            return 0, mean, top\n",
        "def judge(i):\n",
        "    if i % 10 == 1:\n",
        "        return 'st'\n",
        "    elif i % 10 == 2:\n",
        "        return 'nd'\n",
        "    elif i % 10 == 3:\n",
        "        return 'rd'\n",
        "    else:\n",
        "        return 'th'\n",
        "def main():\n",
        "    login_url = 'https://ntrdd.mlsmatrix.com/rets/Login.ashx' \n",
        "    username = '0671181_NID'\n",
        "    password = 'Rt$tg6jx'\n",
        "    rets_client = Session(login_url, username, password)\n",
        "    rets_client.login()\n",
        "    \n",
        "    data = pd.read_csv('df1.csv')        \n",
        "    code = []\n",
        "    name = []\n",
        "    number = []\n",
        "    street = []\n",
        "    city = []\n",
        "    state = []\n",
        "    try:\n",
        "      for item in data['地址']:\n",
        "        a = item.split(',')[0]\n",
        "        b = item.split(',')[2]\n",
        "        c = item.split(',')[1]\n",
        "    except IndexError:\n",
        "        print(\"invalid address!\")\n",
        "    street.append(a)\n",
        "    city.append(c)\n",
        "    numbers = a.split()[0]\n",
        "    names = a.split()[1:(len(a.split()) - 1)]\n",
        "    codes = b.split()[1][0:5]\n",
        "    states = b.split()[0]\n",
        "    state.append(states)\n",
        "    code.append(codes)\n",
        "    name.append(names)\n",
        "    number.append(numbers)\n",
        "    finalN = []\n",
        "    for item in name:\n",
        "      string = \"\"\n",
        "      for items in item:\n",
        "        string += items\n",
        "        string += ' '\n",
        "        finalN.append(string[0:len(string) - 1])            \n",
        "    for i in range(len(code)):\n",
        "      result, mean, top = get(number, finalN, code, i, rets_client, street, city, state)\n",
        "      print('The mean for {}, {}, {} is {}'.format(number[i],finalN[i],code[i], mean))\n",
        "      print('The top 3 for {}, {}, {} are {}'.format(number[i],finalN[i],code[i], top))\n",
        "    return\n",
        "       \n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    print(main())"
      ]
    }
  ]
}