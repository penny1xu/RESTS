{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sql server pull.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/penny1xu/RESTS/blob/main/sql_server_pull.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5ToGbiPEptx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1710c4d6-1106-4ec6-9c93-9e35d3c877f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: censusgeocode in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: requests[security]<3,>=2.27.0 in /usr/local/lib/python3.7/dist-packages (from censusgeocode) (2.28.0)\n",
            "Requirement already satisfied: requests-toolbelt<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from censusgeocode) (0.9.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[security]<3,>=2.27.0->censusgeocode) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rets in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from rets) (0.16.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from rets) (1.15.0)\n",
            "Requirement already satisfied: xmltodict>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from rets) (0.13.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from rets) (2.28.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->rets) (1.24.3)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unixodbc-dev is already the newest version (2.3.7).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyodbc in /usr/local/lib/python3.7/dist-packages (4.0.32)\n"
          ]
        }
      ],
      "source": [
        "#import package\n",
        "!pip install censusgeocode\n",
        "!pip install rets\n",
        "!sudo apt-get install unixodbc-dev\n",
        "!pip install pyodbc\n",
        "import csv\n",
        "import pandas as pd\n",
        "import censusgeocode as cg\n",
        "import numpy as np\n",
        "import sys\n",
        "from rets import Session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
        "curl https://packages.microsoft.com/config/ubuntu/16.04/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
        "sudo apt-get update\n",
        "sudo ACCEPT_EULA=Y apt-get -q -y install msodbcsql17"
      ],
      "metadata": {
        "id": "bJufduI8Jtby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b88d14-02f8-4bf0-9424-4890e48eab4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://packages.microsoft.com/ubuntu/16.04/prod xenial InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "msodbcsql17 is already the newest version (17.8.1.1-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "\r100   983  100   983    0     0   4636      0 --:--:-- --:--:-- --:--:--  4636\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100    79  100    79    0     0    975      0 --:--:-- --:--:-- --:--:--   987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyodbc \n",
        "import pandas as pd \n",
        "conn = pyodbc.connect(DRIVER = '{ODBC Driver 17 for SQL Server}',\n",
        "                      SERVER = '76.184.235.171,1433',\n",
        "                      DATABASE = 'RES_DB',\n",
        "                      UID = 'user123',\n",
        "                      PWD = 'Sunique123')\n",
        "\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT * FROM [RES_DB].[dbo].[Inventory] WHERE [IsSold] = 1\")\n",
        "rows = cursor.fetchall()\n",
        "df = pd.DataFrame()\n",
        "address = []\n",
        "for row in rows:\n",
        "  address.append(row[1])   \n",
        "cursor.close()\n",
        "df['地址'] = address\n",
        "df.to_csv('df1.csv')"
      ],
      "metadata": {
        "id": "jXNgXVjkJt_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cob7JdYQuRAG",
        "outputId": "622900d6-d3c1-45c7-9943-64ded713a021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "invalid address!\n",
            "check coordinates\n",
            "invalid address\n",
            "The mean for 4368, N, 75043 is 0\n",
            "The top 3 for 4368, N, 75043 are 0\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def findifNull(lo_left, lo_right, la_left, la_right, research, zip):\n",
        "    result = research.search(resource='Property', resource_class='Property', dmql_query='(MlsStatus = SLD), (CloseDate = 2022-01-01-2022-05-31), (Longitude = {}+), (Longitude = {}-), (Latitude = {}+), (Latitude = {}-), (PostalCode = {})'.format(lo_left, lo_right, la_left, la_right, zip))\n",
        "    count = 0\n",
        "    lis = []\n",
        "    di = {}\n",
        "    df = pd.DataFrame()\n",
        "    for item in result:\n",
        "        if(item['PropertyType'] == 'Residential' and item['PropertySubType'] == 'Single Family Residence'):\n",
        "            df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True)\n",
        "            count += 1\n",
        "            di = item\n",
        "    for key in di:\n",
        "        lis.append(key)\n",
        "    if(count >= 5):\n",
        "        df = df.T\n",
        "        df.columns = lis\n",
        "        return df\n",
        "    else:\n",
        "        lo_left -= 0.008\n",
        "        lo_right += 0.008\n",
        "        la_left -= 0.008\n",
        "        la_right += 0.008\n",
        "        return findifNull(lo_left, lo_right, la_left, la_right, research, zip)\n",
        "\n",
        "def nullZiphouse(house_leftLa,house_rightLa,house_leftLo,house_rightLo,research,column):\n",
        "  result = research.search(resource = 'Property', resource_class='Property', dmql_query='(MlsStatus = SLD), (CloseDate = 2022-01-01-2022-06-30), (Longitude = {}+), (Longitude = {}-), (Latitude = {}+), (Latitude = {}-)'.format(house_leftLo, house_rightLo, house_leftLa, house_rightLa))\n",
        "  count = 0\n",
        "  df = pd.DataFrame()\n",
        "  for item in result: \n",
        "    if(item['PropertyType'] == 'Residential' and item['PropertySubType'] == 'Single Family Residence'):\n",
        "            df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True) #?\n",
        "            count += 1         \n",
        "  if(count >= 5):  \n",
        "    df = df.T\n",
        "    df.columns = column # \n",
        "    return df\n",
        "  else:\n",
        "    house_leftLo -= 0.008\n",
        "    house_rightLo += 0.008\n",
        "    house_leftLa -= 0.008\n",
        "    house_rightLa += 0.008\n",
        "    return nullZiphouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, research, column)\n",
        "    \n",
        "def findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, house_leftSqt, house_rightSqt, research, column, zip, a, b, time1, time2):\n",
        "    basic = house_leftSqt\n",
        "    count = 0\n",
        "    df = pd.DataFrame()\n",
        "    result = research.search(resource='Property', resource_class='Property', dmql_query='(MlsStatus = SLD), (CloseDate = 2022-01-01-2022-05-31), (YearBuilt = {}+), (YearBuilt = {}-), (Longitude = {}+), (Longitude = {}-), (Latitude = {}+), (Latitude = {}-), (LivingArea = {}+), (LivingArea = {}-), (PostalCode = {})'.format(time1, time2, house_leftLo, house_rightLo, house_leftLa, house_rightLa, house_leftSqt, house_rightSqt, zip))\n",
        "    for item in result:\n",
        "        if(item['PropertyType'] == 'Residential' and item['PropertySubType'] == 'Single Family Residence'):\n",
        "            df = pd.concat([df, pd.DataFrame(item.values())], axis=1, ignore_index=True)\n",
        "            count += 1\n",
        "    if(count >= 5):\n",
        "        df = df.T\n",
        "        df.columns = column\n",
        "        return df\n",
        "    else:\n",
        "        house_leftLa -= 0.008\n",
        "        house_rightLa += 0.008\n",
        "        house_leftLo -= 0.008\n",
        "        house_rightLo += 0.008\n",
        "        b +=1\n",
        "        if(b >= 12):\n",
        "          house_leftLo += 0.096\n",
        "          house_rightLo -= 0.096\n",
        "          house_leftLa += 0.096\n",
        "          house_rightLa -= 0.096  \n",
        "          return nullZiphouse(house_leftLa,house_rightLa,house_leftLo,house_rightLo,research,column)\n",
        "\n",
        "  #Living Area\n",
        "        if(a == 0):\n",
        "            if(basic <= 1100):\n",
        "                house_leftSqt -= 100\n",
        "                house_rightSqt += 100\n",
        "            elif(basic <= 2200):\n",
        "                house_leftSqt -= 200\n",
        "                house_rightSqt += 200\n",
        "            else:\n",
        "                house_leftSqt -= 300\n",
        "                house_rightSqt += 300\n",
        "\n",
        "            a += 1\n",
        "        return findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, house_leftSqt, house_rightSqt, research, column, zip, a, b, time1, time2)\n",
        "\n",
        "    \n",
        "def findfirst(result):\n",
        "    count = 0\n",
        "    for item in result:\n",
        "        count += 1\n",
        "    if(count == 0):\n",
        "        return False\n",
        "    else:\n",
        "        return True    \n",
        "    \n",
        "def insertId(pulled_value, mls, rets_client):\n",
        "    \n",
        "    column = []\n",
        "    for key in pulled_value:\n",
        "        column.append(key)\n",
        "    print(\"\\nThis value exists in Website\")\n",
        "  # get whole row value\n",
        "  #get each value\n",
        "    zip = pulled_value.get('PostalCode')\n",
        "    house_leftLa = float(pulled_value.get('Latitude'))\n",
        "    house_rightLa = float(pulled_value.get('Latitude')) \n",
        "    house_leftLo = float(pulled_value.get('Longitude'))\n",
        "    house_rightLo = float(pulled_value.get('Longitude'))\n",
        "    house_leftSqt = float(pulled_value.get('LivingArea'))\n",
        "    house_rightSqt = float(pulled_value.get('LivingArea'))\n",
        "    time1 = int(pulled_value.get('YearBuilt'))\n",
        "    time2 = int(pulled_value.get('YearBuilt'))\n",
        "    if time1 < 1990:\n",
        "        time1 = 0 \n",
        "        time2 = 1989\n",
        "    elif time1 >=1990 and time1 <2011:\n",
        "        time1 = 1990\n",
        "        time2 = 2010\n",
        "    elif time1 >= 2011 and time1 < 2022:\n",
        "        time1 = 2011\n",
        "        time2 = 2021\n",
        "    else:\n",
        "        time1 = 2022\n",
        "        time2 = 9999\n",
        "    a = 0\n",
        "    b = 0\n",
        "    result1 = findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, house_leftSqt, house_rightSqt, rets_client, column, zip, a, b, time1, time2)        \n",
        "    result1 = result1[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt']]\n",
        "    price = []\n",
        "    for item in result1['ClosePrice']:\n",
        "        item = float(item)\n",
        "        price.append(item)\n",
        "    result1['ClosePrice'] = price\n",
        "    mean1 = result1['ClosePrice'].mean()\n",
        "    top1 = list(result1['ClosePrice'])\n",
        "    top1.sort(reverse = True)\n",
        "    print('The mean for {} is {}'.format(mls, mean1))\n",
        "    print('The top 3 for {} are {}'.format(mls, top1[0:3]))\n",
        "    return result1.to_csv('{}.csv'.format(mls))\n",
        "\n",
        "def findAdd(address, city, state, zip, rets_client):\n",
        "    result = cg.address(address, city = city, state= state,zipcode = zip)\n",
        "    lo_left = result[0]['coordinates']['x']\n",
        "    lo_right = result[0]['coordinates']['x']\n",
        "    la_left = result[0]['coordinates']['y']\n",
        "    la_right = result[0]['coordinates']['y']\n",
        "    result = findifNull(lo_left, lo_right, la_left, la_right, rets_client, zip)\n",
        "    result = result[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt']]\n",
        "    price = []\n",
        "    for item in result['ClosePrice']:\n",
        "        item = float(item)\n",
        "        price.append(item)\n",
        "    result['ClosePrice'] = price\n",
        "    mean = result['ClosePrice'].mean()\n",
        "    top = list(result['ClosePrice'])\n",
        "    top.sort(reverse = True)\n",
        "    print('The mean for {}, {}, {} is {}'.format(address, state, zip, mean))\n",
        "    print('The top 3 for {}, {}, {} are {}'.format(address, state, zip, top))\n",
        "    return result.to_csv('{},{},{}.csv'.format(address, state, zip))\n",
        "    \n",
        "def get(number, finalN, code, i, rets_client, street, city, state):\n",
        "    pulled_value = {}\n",
        "    result = rets_client.search(resource='Property', resource_class='Property', dmql_query='(StreetNumber = {}),(StreetName = {}),(PostalCode = {})'.format(number[i],finalN[i],code[i]))\n",
        "    for item in result:\n",
        "        pulled_value = item\n",
        "    if(len(pulled_value) != 0):\n",
        "        column = []\n",
        "        for key in pulled_value:\n",
        "            column.append(key)\n",
        "        print(\"\\nThis value exists in Website\")\n",
        "  # get whole row value\n",
        "  #get each value\n",
        "        zip = pulled_value.get('PostalCode')\n",
        "        house_leftLa = float(pulled_value.get('Latitude'))\n",
        "        house_rightLa = float(pulled_value.get('Latitude')) \n",
        "        house_leftLo = float(pulled_value.get('Longitude'))\n",
        "        house_rightLo = float(pulled_value.get('Longitude'))\n",
        "        house_leftSqt = float(pulled_value.get('LivingArea'))\n",
        "        house_rightSqt = float(pulled_value.get('LivingArea'))\n",
        "        time1 = int(pulled_value.get('YearBuilt'))\n",
        "        time2 = int(pulled_value.get('YearBuilt'))\n",
        "        if time1 < 1990:\n",
        "            time1 = 0 \n",
        "            time2 = 1989\n",
        "        elif time1 >=1990 and time1 <2011:\n",
        "            time1 = 1990\n",
        "            time2 = 2010\n",
        "        elif time1 >= 2011 and time1 < 2022:\n",
        "            time1 = 2011\n",
        "            time2 = 2021\n",
        "        else:\n",
        "            time1 = 2022\n",
        "            time2 = 9999\n",
        "        a = 0\n",
        "        b = 0\n",
        "        result1 = findHouse(house_leftLa, house_rightLa, house_leftLo, house_rightLo, house_leftSqt, house_rightSqt, rets_client, column, zip, a, b, time1, time2)\n",
        "        result1 = result1[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt']]\n",
        "        price = []\n",
        "        for item in result1['ClosePrice']:\n",
        "            item = float(item)\n",
        "            price.append(item)\n",
        "        result1['ClosePrice'] = price\n",
        "        mean1 = result1['ClosePrice'].mean()\n",
        "        top1 = list(result1['ClosePrice'])\n",
        "        top1.sort(reverse = True)\n",
        "        return result1.to_csv('{} {} {}.csv'.format(number[i],finalN[i],code[i])), mean1, top1[0:3]\n",
        "    else:\n",
        "        print('check coordinates')\n",
        "        result = cg.address(street[i], city = city[i], state= state[i], zipcode = code[i])\n",
        "        if(len(result) != 0):\n",
        "            lo_left = result[0]['coordinates']['x']\n",
        "            lo_right = result[0]['coordinates']['x']\n",
        "            la_left = result[0]['coordinates']['y']\n",
        "            la_right = result[0]['coordinates']['y']\n",
        "            result = findifNull(lo_left, lo_right, la_left, la_right, rets_client, code[i])\n",
        "            result = result[['BathroomsFull','BathroomsHalf', 'BathroomsTotalDecimal', 'BathroomsTotalInteger','BedroomsTotal', 'BuildingAreaTotal', 'City', 'CloseDate', 'ClosePrice', 'CumulativeDaysOnMarket', \n",
        "   'DaysOnMarket', 'GarageSpaces', 'Latitude', 'ListingContractDate', 'ListingId', 'ListPrice', \n",
        "   'ListSource', 'LivingArea', 'Longitude', 'LotSizeAcres', 'MlsStatus', 'OwnerName', 'OwnerPhone', 'OwnerPhoneAlternative',\n",
        "   'ParcelNumber', 'ParcelNumber2', 'PoolYN', 'PostalCode', 'PreviousListPrice', 'PreviousStatus', 'PropertySubType',\n",
        "   'PropertyType', 'PublicRemarks', 'PurchaseContractDate', 'SchoolDistrict', 'StandardStatus', 'StatusChangeTimestamp',\n",
        "   'StreetDirPrefix', 'StreetDirSuffix', 'StreetName', 'StreetNumber', 'StreetNumberNumeric', 'StreetSuffix', 'SubdivisionName',\n",
        "   'USProperty_MUI', 'YearBuilt']]\n",
        "            price = []\n",
        "            for item in result['ClosePrice']:\n",
        "                item = float(item)\n",
        "                price.append(item)\n",
        "            result['ClosePrice'] = price\n",
        "            mean = result['ClosePrice'].mean()\n",
        "            top = list(result['ClosePrice'])\n",
        "            top.sort(reverse = True)\n",
        "            return result.to_csv('{} {} {}.csv'.format(number[i],finalN[i],code[i])), mean, top[0:3]\n",
        "        else:\n",
        "            print('invalid address')\n",
        "            mean = 0\n",
        "            top = 0\n",
        "            return 0, mean, top\n",
        "def judge(i):\n",
        "    if i % 10 == 1:\n",
        "        return 'st'\n",
        "    elif i % 10 == 2:\n",
        "        return 'nd'\n",
        "    elif i % 10 == 3:\n",
        "        return 'rd'\n",
        "    else:\n",
        "        return 'th'\n",
        "def main():\n",
        "    login_url = 'https://ntrdd.mlsmatrix.com/rets/Login.ashx' \n",
        "    username = '0671181_NID'\n",
        "    password = 'Rt$tg6jx'\n",
        "    rets_client = Session(login_url, username, password)\n",
        "    rets_client.login()\n",
        "    \n",
        "    data = pd.read_csv('df1.csv')        \n",
        "    code = []\n",
        "    name = []\n",
        "    number = []\n",
        "    street = []\n",
        "    city = []\n",
        "    state = []\n",
        "    try:\n",
        "      for item in data['地址']:\n",
        "        a = item.split(',')[0]\n",
        "        b = item.split(',')[2]\n",
        "        c = item.split(',')[1]\n",
        "    except IndexError:\n",
        "        print(\"invalid address!\")\n",
        "    street.append(a)\n",
        "    city.append(c)\n",
        "    numbers = a.split()[0]\n",
        "    names = a.split()[1:(len(a.split()) - 1)]\n",
        "    codes = b.split()[1][0:5]\n",
        "    states = b.split()[0]\n",
        "    state.append(states)\n",
        "    code.append(codes)\n",
        "    name.append(names)\n",
        "    number.append(numbers)\n",
        "    finalN = []\n",
        "    for item in name:\n",
        "      string = \"\"\n",
        "      for items in item:\n",
        "        string += items\n",
        "        string += ' '\n",
        "        finalN.append(string[0:len(string) - 1])            \n",
        "    for i in range(len(code)):\n",
        "      result, mean, top = get(number, finalN, code, i, rets_client, street, city, state)\n",
        "      print('The mean for {}, {}, {} is {}'.format(number[i],finalN[i],code[i], mean))\n",
        "      print('The top 3 for {}, {}, {} are {}'.format(number[i],finalN[i],code[i], top))\n",
        "    return\n",
        "       \n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    print(main())"
      ]
    }
  ]
}